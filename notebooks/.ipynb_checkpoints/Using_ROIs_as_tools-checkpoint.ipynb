{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Using_ ROIs as tools\n",
    "\n",
    "In the previous chapter (\"ROIs as tools\") we considered ROIs as tools _independent of any specific application_ .  This gave us a feel for both their characteristics as data objects (and how they are generated/formed) _as well as_ the manner in which they represent particular volumes of space in the brain.  Establishing this conceputal link, and how to leverage these tools in concert with our knowledge of brain anatomy is _essential_ to performing advanced, automated, and high-quality white matter anatomy segmentations\n",
    "\n",
    "Thus, having established **what** an ROI is.\n",
    "\n",
    "## A first pass use of an ROI in a segmentation\n",
    "\n",
    "In the previous chapter (\"ROIs as tools\") we initially generated (planar) ROIs by arbitrarily selecting a dimension and a coordinate.  For a first pass demonstration of using an ROI to sub-select streamlines we can adopt the same strategy.\n",
    "\n",
    "In the interactive visualization below you will be able to select a coordinate, dimension _and_ an instruction as to whether you would like to **include** or **exclude** streamlines that pass through the plane you have created.  **Be warned**:  if you select a criteria that is particularly generous (in that it sub-selects many streamlines) the selection and/or visualization process may take a moment to execute.  Given that a single exclusion criteria can only be so effective, this is more likely to be an issue using **exclude** than **include**.\n",
    "\n",
    "The next three code cells are divided in such a way as to facilitate ease of use.  They are:\n",
    "\n",
    "- 1. The loading cell, which loads the relevant data objects\n",
    "- 2. The plane definition cell, which allows the user to define and view their planar ROI\n",
    "- 3. The segmentation cell, which applies the planar ROI as a segmentation criterion. \n",
    "\n",
    "In order to perform a preliminary segmentation operation you'll have to load the data in cell 1, define a plane in cell 2, and then apply and view the segmentation in cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading cell: loads relevant objects\n",
    "\n",
    "#this code ensures that we can navigate the WiMSE repo across multiple systems\n",
    "import subprocess\n",
    "import os\n",
    "#get top directory path of the current git repository, under the presumption that \n",
    "#the notebook was launched from within the repo directory\n",
    "gitRepoPath=subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode('ascii').strip()\n",
    "\n",
    "#establish path to the wma_tools repo\n",
    "wma_toolsDirPath=os.path.join(gitRepoPath,'wma_pyTools')   \n",
    "\n",
    "#change to the wma_tools path, load the function set, then change back to the top directory\n",
    "os.chdir(wma_toolsDirPath)\n",
    "import WMA_pyFuncs\n",
    "os.chdir(gitRepoPath)\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn.plotting import plot_roi\n",
    "import matplotlib\n",
    "\n",
    "#establish path to t1\n",
    "t1Path=os.path.join(gitRepoPath,'exampleData','t1.nii.gz')   \n",
    "\n",
    "#import the data\n",
    "t1img = nib.load(t1Path)\n",
    "import numpy as np\n",
    "#done to establish bounds of image in acpc space\n",
    "fullMask = nib.nifti1.Nifti1Image(np.ones(t1img.get_fdata().shape), t1img.affine, t1img.header)\n",
    "#pass full mask to boundary function\n",
    "t1DimBounds=WMA_pyFuncs.returnMaskBoundingBoxVoxelIndexes(fullMask)\n",
    "#convert the coords to subject space in order set max min values for interactive visualization\n",
    "convertedBoundCoords=nib.affines.apply_affine(t1img.affine,t1DimBounds)\n",
    "\n",
    "\n",
    "smallTractogramPath=os.path.join(gitRepoPath,'exampleData','smallTractogram.tck')\n",
    "streamsObjIN=nib.streamlines.load(smallTractogramPath)\n",
    "\n",
    "#get tractogram from the Tck holder\n",
    "sourceTractogram=streamsObjIN.tractogram\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0962cf3b3e45c29f4281e4eedac21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='planeCoord', max=109, min=-126)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.genAndViewPlanarROI(planeCoord, dimension, xCoord, yCoord, zCoord)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveDimDictionary={'x':0,'y':1,'z':2}\n",
    "\n",
    "def genAndViewPlanarROI(planeCoord,dimension,xCoord,yCoord,zCoord):\n",
    "    \n",
    "    from nilearn import plotting\n",
    "    import nibabel as nib\n",
    "    import numpy as np\n",
    "    \n",
    "    #refuse to plot if coord is outside of dim bound\n",
    "    if np.logical_or(np.min(convertedBoundCoords[:,naiveDimDictionary[dimension]])>planeCoord, \\\n",
    "                    np.max(convertedBoundCoords[:,naiveDimDictionary[dimension]])<planeCoord):\n",
    "        print('requested coordinate exceeds selected dimension\\'s bounds')\n",
    "    else:    \n",
    "        segPlane=WMA_pyFuncs.makePlanarROI(t1img, planeCoord, dimension)\n",
    "    \n",
    "        %matplotlib inline\n",
    "        plotting.plot_roi(roi_img=segPlane, bg_img=t1img, cut_coords=[xCoord,yCoord,zCoord])\n",
    "        \n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import Dropdown\n",
    "from ipywidgets import IntSlider\n",
    "\n",
    "#establish objects for visualization interaction\n",
    "\n",
    "dimList=list(['x','y','z'])\n",
    "\n",
    "dimension=Dropdown(options=dimList, description=\"dimension for plane\")\n",
    "planeCoord=IntSlider(min=np.min(convertedBoundCoords.astype(int)), max=np.max(convertedBoundCoords.astype(int)), step=1,continuous_update=False)\n",
    "  \n",
    "\n",
    "interact(genAndViewPlanarROI, \\\n",
    "    dimension=dimension, \\\n",
    "    planeCoord=planeCoord,  \\\n",
    "    xCoord=IntSlider(min=np.min(convertedBoundCoords[:,0].astype(int)), max=np.max(convertedBoundCoords[:,0].astype(int)), step=1,continuous_update=False),  \\\n",
    "    yCoord=IntSlider(min=np.min(convertedBoundCoords[:,1].astype(int)), max=np.max(convertedBoundCoords[:,1].astype(int)), step=1,continuous_update=False), \\\n",
    "    zCoord=IntSlider(min=np.min(convertedBoundCoords[:,2].astype(int)), max=np.max(convertedBoundCoords[:,2].astype(int)), step=1,continuous_update=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d32bd464dfc4488b30db5736a46a2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='instruction', options=('Include', 'Exclude'), value='Include'), Ou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.updateFunction(instruction)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate the roi from the preceeding visualization using the output\n",
    "segPlane=WMA_pyFuncs.makePlanarROI(t1img, planeCoord.value, dimension.value)\n",
    "    \n",
    "#quick and dirty tractogram subsetter by Brad Caron\n",
    "#https://github.com/bacaron\n",
    "def extractSubTractogram(sourceTractogram,indexes):\n",
    "    #import relevant package\n",
    "    import nibabel as nib\n",
    "    #extrect the desired streamlines into a new streamline object\n",
    "    streamlines = sourceTractogram.streamlines[indexes]\n",
    "    #establish tractogram object\n",
    "    out_tractogram = nib.streamlines.tractogram.Tractogram(streamlines)\n",
    "    #adjust the relevant header fields\n",
    "    #don't bother for now, header is only relevant to Tck file\n",
    "    #for headerFields in ['total_count','count','nb_streamlines']:\n",
    "        #nb_streamlines is an int, whereas the others are strings, for some reason\n",
    "    #    if headerFields == 'nb_streamlines':\n",
    "    #        out_tractogram.header[headerFields] = len(streamlines)\n",
    "    #    else:\n",
    "    #        out_tractogram.header[headerFields] = '%s' %len(streamlines)\n",
    "    return out_tractogram\n",
    "\n",
    "#interactive plotting via niwidgets?  \n",
    "#widget within a widget doesn't seem to work\n",
    "def plotParcellationConnectionWidget(subTractogram):\n",
    "    #import widget\n",
    "    from niwidgets import StreamlineWidget\n",
    "    #set widget object\n",
    "    \n",
    "    sw = StreamlineWidget(streamlines=subTractogram)\n",
    "    #set plotting characteristics\n",
    "    style = {'axes': {'color': 'red',\n",
    "                  'label': {'color': 'white'},\n",
    "                  'ticklabel': {'color': 'white'},\n",
    "                  'visible': True},\n",
    "         'background-color': 'black',\n",
    "         'box': {'visible': True}}\n",
    "    #plot it\n",
    "    sw.plot(display_fraction=1, width=1000, height=1000, style=style, percentile=0)\n",
    "    #sw.plot(display_fraction=1, width=1000, height=1000, percentile=0)\n",
    "    \n",
    "\n",
    "    \n",
    "def updateFunction(instruction):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import ipyvolume as ipyv  \n",
    "\n",
    "    if instruction == 'Include':\n",
    "        instruction=True\n",
    "    else:\n",
    "        instruction=False\n",
    "\n",
    "    #use the criteria application function to find the relevant streamlines\n",
    "    streamBool=WMA_pyFuncs.applyNiftiCriteriaToTract(sourceTractogram.streamlines, segPlane, instruction, 'any')\n",
    "    \n",
    "    streamsToPlot=extractSubTractogram(sourceTractogram,np.where(streamBool)[0])\n",
    "    \n",
    "    plotParcellationConnectionWidget(streamsToPlot.streamlines)\n",
    "    \n",
    "    from niwidgets import NiftiWidget\n",
    "    \n",
    "    #curFig=ipyv.pylab.gcf()\n",
    "    #ipyv.pylab.view(distance=100)\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import Dropdown\n",
    "from ipywidgets import IntSlider\n",
    "\n",
    "#establish objects for visualization interaction\n",
    "\n",
    "instructionList=list(['Include','Exclude'])\n",
    "\n",
    "interact(updateFunction, \\\n",
    "    instruction=Dropdown(options=instructionList, description=\"instruction\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the planar ROI, what we have essentially done is defined a coordinate in a single dimension that is of particular interest to is.  For example, if we created a planar ROI at 10 Y in [ACPC space](https://bids-specification.readthedocs.io/en/latest/99-appendices/08-coordinate-systems.html#ieeg-specific-coordinate-systems) we would obtain a large number of points.  Specifically the X and Z coordinates for these points would correspond to all possible combinations of X and Z values between the minimum and maximum dimensions of the associated source image (i.e. a T1 or DWI image), sampled at some regular interval (i.e. 1 mm).  The Y coordinates, on the other hand, would all be 10.  So how can we use this?\n",
    "\n",
    "#### Asking a question with an ROI\n",
    "\n",
    "Now that we have our ROI we are now capable of asking (in a mathematical sense) a very specific question:  **which of our streamlines cross (i.e. \"intersect with\") this plane?**  We do this by determining, for each streamline, if **any** coordinate from the streamline is within some distance threshold (i.e. .5 mm) of any coordinate of the ROI.  In practice, this ends up being moderately computationally expensive.  Why?  Because, for each coordinate of the streamline, our intersection algorithm has to compute the distance between that coordinate, and each coordinate of the ROI (which equals [number of streamline nodes] * [number of ROI coordinates] computations).  As a consequence of this, the smaller the step size between the nodes in a streamline or the more densely sampled the ROI is, the longer this operation takes.  Once we have applied this opertion, we can then select those streamlines which meet the specified criteria.\n",
    "\n",
    "> **A VERY IMPORTANT CAVIOT**:  A careful and attentive reader of the preceeding paragraph will note that it wasn't entirely true.  Specifically, if you translate the mathematical operation it described, you'll realize that what we really asked was \"**Which of our streamlines have nodes that are within [some distance] of a coordinate of this ROI?**\".  There are certian circumstances where the operation would return a true (i.e. \"this streamline meets the specified criteria\") for a given streamline even though the streamline didn't actually \"intersect\" the ROI.  How?  Imagine that we had a planar ROI and a streamline that traveled perfectly perpendicular with it, such that it got to within the threshold distance of the planar ROI _but never actually crossed it_.  Indeed, the streamline doesn't even need to travel alongside the planar ROI the entire time--it could just move to within the threshold distance, and then move away again (so long as at least one node meets this criteria).  In either case the algorithm we just described would still return a True for that streamline.  But this isn't the only problem.\n",
    "\n",
    "> In addition to the aforementioned possibility, it's also possible that this algorithm (which is, in essence, the one that is typically used in segmentation) might **fail to detect** a streamlinehet that we would consider to be intersecting with the ROI.  How?  If we think back to our previous discussion of step-sizes between streamline nodes, we realize that its possible for there to actually be fairly sizable amounts of distance between nodes, particularly if the streamlines have been [\"compressed\"](https://dipy.org/documentation/1.0.0./examples_built/streamline_length/).  If the inter-node distance is enough to where the streamline \"traverses\" the ROI (i.e. there are nodes on either side of the ROI), but no individual node is within the distance threshold, then the algorithm will fail to detect this intersection.  For example, if the nearest nodes on either side of a planar ROI are 2 mm from the plane, but the threshold distance is .5, the \"intersection\" will go unnoticed.  This is particularly an issue with planar ROIs, but less so with fuller, volumetric ROIS (e.g. spheres).  \n",
    "\n",
    "For the moment, there's really nothing we can do about these possibilities.  In the first case, we may not be too worried about it, since .5 is pretty close, and we'd probably be comfortable calling that an intersection.  In the latter case, we're probably not comfortable with that outcome, but we can safeguard against it by ensuring that our streamlines are sampled at a rate that takes into account the threshold distance of our intersection algorithm.  Regardless, its time to make and examine our first planar ROI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
