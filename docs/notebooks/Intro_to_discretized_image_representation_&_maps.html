
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction to discretized image representation and maps &#8212; White Matter Segmentation Education (WiMSE)</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Aligning two images" href="Aligning_two_images.html" />
    <link rel="prev" title="Building bridges from the familiar to the unfamiliar" href="Building_Bridges.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">White Matter Segmentation Education (WiMSE)</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../landingPage.html">
   White Matter Segmentation Education (WiMSE)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Front matter
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Author_and_funding_information.html">
   Author and Funding information
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapterSummaries.html">
   White Matter Segmentation Education - WiMSE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Building_Bridges.html">
   Building bridges from the familiar to the unfamiliar
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Building intuitions with digital images
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Introduction to discretized image representation and maps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Aligning_two_images.html">
   Aligning two images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Multi_object_maps_in_images.html">
   Multi object maps in images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="A_consideration_of_jpegs_and_brain_images.html">
   A consideration of jpegs and brain images
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Working with NIfTI data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="How_to_represent_the_brain%27s_anatomy_-_as_a_volume.html">
   How to represent the brain’s anatomy - as a volume
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="How_to_interpret_a_volumetric_brain_segmentation.html">
   How to interpret a volumetric brain segmentation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  White matter and tractography
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="The_voxel_and_the_streamline.html">
   The voxel and the streamline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="The_source_tractogram.html">
   The source tractogram
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Segmenting tractography
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="A_first_segmentation.html">
   A first segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Biological_Plausibility_for_Tractograms.html">
   Biological Plausibility for Tractograms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ROIs_as_tools.html">
   ROIs as tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Using_ROIs_as_tools.html">
   <em>
    Using
   </em>
   ROIs as tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="A_second_segmentation-categorical_segmentation.html">
   A second segmentation - categorical segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Advanced_anatomically-based_segmentation.html">
   Advanced anatomically-based segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Example_Segmentation-uncinate_fasiculus.html">
   Example Segmentation: uncinate fasciculus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Example_Segmentation-IFOF.html">
   Example Segmentation: inferior fronto-occipital fasciculus (IFOF)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Epilogue
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Closing_Thoughts.html">
   Closing Thoughts
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/Intro_to_discretized_image_representation_&_maps.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        
        <a class="edit-button" href="https://github.com/DanNBullock/WiMSE/edit/master/notebooks/Intro_to_discretized_image_representation_&_maps.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/DanNBullock/WiMSE/master?urlpath=tree/notebooks/Intro_to_discretized_image_representation_&_maps.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-a-satellite-image">
   Why a satellite image?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#jpegs-color-and-data-dimensions">
   JPEGs, color, and data dimensions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lets-plot-each-of-these-color-layers-separately-and-take-a-look-at-the-output">
     Lets plot each of these color layers separately and take a look at the output.
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-three-layers">
   Why three layers?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-happens-when-you-look-at-a-specific-pixel-across-the-color-layers">
     What happens when you look at a specific pixel across the color layers?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-s-in-a-pixel">
   What’s in a pixel?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#use-the-sliders-below-to-enter-in-the-values-obtained-for-the-pixels-listed-above-in-order-to-identify-the-corresponding-colors">
     Use the sliders below to enter in the values obtained for the pixels listed above in order to identify the corresponding colors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-colors-do-you-get-for-these-points">
     What colors do you get for these points?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-the-colors-for-these-pixels">
     What are the colors for these pixels?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-color-of-data">
   The color of data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-types-of-environments-are-found-at-each-of-these-pixels">
     What types of environments are found at each of these pixels?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-biome-s-color">
   A biome’s color
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-might-we-use-this-here-with-the-satellite-data">
     How might we use this here with the satellite data?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#can-we-select-all-of-the-pixels-that-correspond-to-a-specific-biome">
     Can we select
     <em>
      all
     </em>
     of the pixels that correspond to a specific biome?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#which-environment-is-the-most-homogenous">
     Which environment is the most homogenous?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-would-create-a-rule-or-series-of-rules-i-e-an-algorithm-to-find-all-of-the-image-pixels-that-correspond-to-this-environment-type">
     How would create a rule, or series of rules (i.e. an
     <em>
      algorithm
     </em>
     ), to find all of the image pixels that correspond to this environment type?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-potential-target">
     A potential target?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-can-we-find-all-pixels-of-that-type">
     <em>
      How
     </em>
     can we find all pixels of that type?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-many-pixels-do-you-expect-this-to-be">
     How many pixels do you expect this to be?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#an-unexpected-result">
     An unexpected result?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-possible-explanation">
       A possible explanation?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#so-how-do-we-find-the-remaining-70-8-of-pixels">
       So how do we find the remaining 70.8% of pixels?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#how-did-we-count-the-number-of-atlantic-blue-pixels">
       How did we count the number of “Atlantic blue” pixels?
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#checking-our-math">
     Checking our math
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#how-can-we-include-pixel-colors-that-are-nearby-atlantic-blue-14-49-69-in-our-count">
       How can we include pixel colors that are “nearby” Atlantic blue [14 49 69] in our count?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#how-can-we-define-close-in-a-math-like-way">
       How can we define “close” in a math-like way?
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-trigonometry-to-compute-color-distances">
   Using trigonometry to compute color distances
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-do-we-actually-get-from-zerobluemask-np-subtract-firstmaparray-atlanticcolor">
     What do we actually get from “zeroBlueMask=np.subtract(firstMapArray,atlanticColor)”
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-rough-first-step">
     A rough first step
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#can-we-generalize-this-concept">
     Can we generalize this concept?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualizing-color-distances">
   Visualizing color distances
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-big-cluster-from-0-to-75-is-the-one-we-are-interested-in-and-to-see-why-we-can-look-at-the-plot-below-the-histogram">
     The big cluster, from 0 to 75 is the one we are interested in, and to see why we can look at the plot below the histogram.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-s-the-ideal-distance-from-atlantic-blue-to-capture-as-many-water-pixels-as-possible-and-as-few-land-pixels-as-possible">
     What’s the ideal distance from “Atlantic blue” to capture as many water pixels as possible and as few land pixels as possible?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#making-an-ocean-mask">
   Making an ocean mask
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-ideal-threshold-value">
     What is the ideal threshold value?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-might-the-histogram-clusters-correspond-to">
     What might the histogram clusters correspond to?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-good-guesses-as-to-what-the-clusters-correspond-to">
     Some good guesses as to what the clusters correspond to:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-good-guess-as-to-the-best-threshold-value">
     A good guess as to the best threshold value
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="introduction-to-discretized-image-representation-and-maps">
<h1>Introduction to discretized image representation and maps<a class="headerlink" href="#introduction-to-discretized-image-representation-and-maps" title="Permalink to this headline">¶</a></h1>
<div class="section" id="why-a-satellite-image">
<h2>Why a satellite image?<a class="headerlink" href="#why-a-satellite-image" title="Permalink to this headline">¶</a></h2>
<p>If you’ve happened to scroll over this lesson you’ll note that we’re starting by looking at satellite images.  Surely, given that we’re studying the brain, wouldn’t it be more appropriate to look at an image of a brain?  If our goal was to jump straight into learning about the brain, maybe, but as we noted earlier, our first goal is to learn about image formats.  This is because many of the things we can do with 2-D images we can also do with 3-D images.  While some of us may have been looking at pictures of the brain for years now–perhaps even decades–it’s almost guaranteed that we’ve been looking at pictures of the world for far longer.  As such, we’re beginning with pictures of the world, which we presumably have deeper-seated intuitions about.</p>
<p>In the following sections we’ll consider how the actual data in the digital image structure corresponds to things like oceans, forests and other types of <a class="reference external" href="https://en.wikipedia.org/wiki/Biome">biomes</a>.  We’ll see how we can use our intuitions to bridge the gap between the raw, numerical data and our existing understanding of the world itself (i.e. the subject of the satellite photography).</p>
<p>Ultimately, what we will be illustrating are the processes of <strong>spatial translation</strong> (moving an object in space) and <strong>masking</strong> (the selection or “indexing” of related sub-components from a larger whole).  These concepts are introduced here in 2D using the satellite image, but as later lessons will show, these concepts are absolutely fundamental to our use of neuroimaging data.  As a quick illustration of this, when we initially use an MRI scanner to obtain an image of a person’s head, we also get data about the person’s neck, head, skull and other tissues that <em>are not</em> the brain.  However, when we do our analyses, we only want to look at data that relates to the brain.  As such, we have to “<strong>mask</strong> out” those spatial regions of the scan data that we are not interested in.  Doing so ensures that we only extract data from the structures/areas of interest.  Before we get there though, let’s build our intuitions.  We’ll begin here with an introduction to this process with the ocean and landmasses.</p>
<p>Let’s begin by loading and plotting <a class="reference external" href="https://commons.wikimedia.org/wiki/File:Earthmap1000x500.jpg">a satellite image</a> now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#this code ensures that we can navigate the WiMSE repo across multiple systems</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="c1">#get top directory path of the current git repository, under the presumption that </span>
<span class="c1">#the notebook was launched from within the repo directory</span>
<span class="n">gitRepoPath</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">([</span><span class="s1">&#39;git&#39;</span><span class="p">,</span> <span class="s1">&#39;rev-parse&#39;</span><span class="p">,</span> <span class="s1">&#39;--show-toplevel&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;ascii&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

<span class="c1">#move to the top of the directory</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">gitRepoPath</span><span class="p">)</span>

<span class="c1">#file name of standard map of the world</span>
<span class="n">firstMapName</span><span class="o">=</span><span class="s1">&#39;Earthmap1000x500.jpg&#39;</span>

<span class="c1">#file name of grayscale map of the world</span>
<span class="n">grayscaleMapName</span><span class="o">=</span><span class="s1">&#39;World_map_blank_without_borders.svg.png&#39;</span>

<span class="c1">#file name of world map with &quot;graticule&quot; (lines)</span>
<span class="c1">#see https://en.wikipedia.org/wiki/Geographic_coordinate_system for more info</span>
<span class="n">linedMapName</span><span class="o">=</span><span class="s1">&#39;Equirectangular_projection_SW.jpg&#39;</span>

<span class="c1">#file name of political world map</span>
<span class="n">politicalMapName</span><span class="o">=</span><span class="s1">&#39;2000px-Dünya.svg.png&#39;</span>

<span class="c1">#loading image processing and manipulation package Pillow</span>
<span class="c1"># https://pillow.readthedocs.io/en/stable/</span>
<span class="kn">import</span> <span class="nn">PIL</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="k">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">matplotlib.pyplot</span> <span class="k">import</span> <span class="n">imshow</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">firstMapPath</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gitRepoPath</span><span class="p">,</span><span class="s1">&#39;images&#39;</span><span class="p">,</span><span class="n">firstMapName</span><span class="p">)</span> 
<span class="n">firstMap</span><span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">firstMapPath</span><span class="p">)</span>

<span class="c1">#in order to display in jupyter, some trickery is necessary</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">firstMap</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Intro_to_discretized_image_representation_&amp;_maps_1_0.png" src="../_images/Intro_to_discretized_image_representation_&amp;_maps_1_0.png" />
</div>
</div>
<p>Here we see a satellite image of the world just like any other that you’ve seen before.  Note though, that it is bordered by numbered axes, with zeros in the upper (for the Y axis) and lower (for the X axis) left-hand corners. This is because we have loaded it here in a jupyter notebook, which treats it just like any other pixel-wise plot that could be generated from code or data.  As such, the labeling numbers we see tracking the pixel rows in columns in the image.  It’s just that, in this case, the color for each data point (in each row and column) corresponds to the color of the earth’s surface at that location.  From this plotting we can see that our code has loaded the image as a 500 pixel tall by 1000 pixel wide object.</p>
<p>Take note of how, <em>specifically</em>, the row and column numberings are associated with the plotted image.  We can see that the top row is labeled zero, while the final row is unlabeled, but nonetheless corresponds to 500.  Likewise, the first column is labeled zero, but the final (unlabeled) column corresponds to 1000.  Though this method of orientation may feel unintuitive, this is how data is plotted with <a class="reference external" href="https://matplotlib.org/">matplotlib</a> (the code library we are using to view these images) (<a class="reference external" href="https://doi.org/10.1109/MCSE.2007.55">Hunter, JD, 2007</a>).</p>
<p>Lets use some additional <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html">python functions</a> to extract the <a class="reference external" href="https://en.wikipedia.org/wiki/RGB_color_model">“raw” data</a> being used to generate this plot and examine it.  We’ll begin by looking at the dimensions of the image according to the python function (which reports image dimensions), and we’ll look at the dimensions of the underlying data itself.</p>
<p><strong>Do we expect these two entries to be the same or different–is the data structure <em>exactly</em> the same size as the image?  Why or why not?</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dimensions of image&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">firstMap</span><span class="o">.</span><span class="n">format</span><span class="p">,</span><span class="n">firstMap</span><span class="o">.</span><span class="n">size</span> <span class="p">,</span> <span class="n">firstMap</span><span class="o">.</span><span class="n">mode</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="n">firstMapArray</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">firstMap</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dimensions of array&#39;</span><span class="p">)</span>
<span class="n">firstMapShape</span><span class="o">=</span><span class="n">firstMapArray</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="n">firstMapShape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dimensions of image
JPEG (1000, 500) RGB

Dimensions of array
(500, 1000, 3)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="jpegs-color-and-data-dimensions">
<h2>JPEGs, color, and data dimensions<a class="headerlink" href="#jpegs-color-and-data-dimensions" title="Permalink to this headline">¶</a></h2>
<p>The <strong>first output</strong>  we get (providing <strong>image</strong> information) reads as follows:</p>
<p>“JPEG (1000, 500) RGB”</p>
<p>This provides us with several details.  It comes from the default python functions associated with inspecting data objects and their characteristics.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/JPEG"><strong>JPEG</strong></a>:  Indicates the file type, which could have also been <a class="reference external" href="https://en.wikipedia.org/wiki/Portable_Network_Graphics">PNG</a> for example.</p></li>
<li><p><strong>(1000, 500)</strong>: This quantity indicates the <a class="reference external" href="https://en.wikipedia.org/wiki/Image_resolution">resolution of the image</a>.  The first number indicates how many pixels wide it is, while the second indicates how tall it is in pixels.</p></li>
<li><p><strong>RGB</strong>:  Indicates the <a class="reference external" href="https://en.wikipedia.org/wiki/RGB_color_model">color component channels</a> that are being combined to create the image.  Here we see that there are three of these channels and they correspond to the Red (R), Green (G), and Blue (B).</p></li>
</ul>
<p>The <strong>second output</strong> reads as “(500, 1000, 3)” and indicates the dimensions of the image’s <em>actual</em> data representation.  That is, the structured and quantitative information that preserves the relevant correspondances with the source entity/object.</p>
<p>Here we see that it is a <strong>3</strong> dimensional array.  This may come as a surprise given that the image is clearly <strong>2</strong> dimensional.  The first two values (500 and 1000) correspond to the height and width of the image.  Note that this ordering is flipped as compared to the output of the previous report.  This is something to be mindful of when investigating data structures, as the norms for the ordering of dimensions vary from function to function and programming language to programming language.  The final value, <strong>(3)</strong>, is something new though.  This corresponds to the aforementioned color channels for the image.  This value is 3 because this is an <em>RGB</em> based image.  Had the final entry of the first output been <a class="reference external" href="https://en.wikipedia.org/wiki/CMYK_color_model"><em>CMYK</em> (Cyan Magenta Yellow Black)</a> instead the size of the final dimension would have been 4 instead of 3.  Typically though, CMYK is used for printed (or to be printed) mediums.</p>
<div class="section" id="lets-plot-each-of-these-color-layers-separately-and-take-a-look-at-the-output">
<h3>Lets plot each of these color layers separately and take a look at the output.<a class="headerlink" href="#lets-plot-each-of-these-color-layers-separately-and-take-a-look-at-the-output" title="Permalink to this headline">¶</a></h3>
<p>We’ll plot the red, green, and blue channels separately below, as though they were full maps in and of themselves.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">firstMapArray</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Reds&#39;</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">firstMapArray</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Greens&#39;</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">firstMapArray</span><span class="p">[:,:,</span><span class="mi">2</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Intro_to_discretized_image_representation_&amp;_maps_5_0.png" src="../_images/Intro_to_discretized_image_representation_&amp;_maps_5_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="why-three-layers">
<h2>Why three layers?<a class="headerlink" href="#why-three-layers" title="Permalink to this headline">¶</a></h2>
<p>Each of these color layers looks somewhat similar but contain slightly different information.  For example, if you look closely at the red image, you’ll notice that it does not exhibit the same equatorial “darkening” that the green and blue images do.  Other differences are visible between green and blue images, though they are more subtle.  For example, <a class="reference external" href="https://en.wikipedia.org/wiki/Lake_Victoria">Lake Victoria</a> (in the eastern part of central Africa, at about 600 X and 250 Y) is visible in the green channel but not in the blue channel.  Although these three channels are all carrying information about the world, they each constitute  distinct bodies of information.  This information is combined by the setup of our <a class="reference external" href="https://en.wikipedia.org/wiki/Computer_monitor">computer monitors</a>, and we perceive the resultant combination (through an <a class="reference external" href="https://en.wikipedia.org/wiki/Color_vision">extremely complex process</a>) as the coherent depiction of the planet that we’re all generally familiar with.</p>
<div class="section" id="what-happens-when-you-look-at-a-specific-pixel-across-the-color-layers">
<h3>What happens when you look at a specific pixel across the color layers?<a class="headerlink" href="#what-happens-when-you-look-at-a-specific-pixel-across-the-color-layers" title="Permalink to this headline">¶</a></h3>
<p>Let’s look at the data stored across these three layers, in several specific pixels from the map:</p>
<ul class="simple">
<li><p>the upper left of the map [0,0]</p></li>
<li><p>the atlantic ocean [450,400]</p></li>
<li><p>the United States [150,200]</p></li>
<li><p>Russia [80,700]</p></li>
<li><p>North Africa [180,550]</p></li>
</ul>
<p>Below we’ll index into the data structure for the pixels that were just listed, and then print out the information that is being stored (across all 3 RGB layers) for each.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Upper left pixel RGB Value&#39;</span><span class="p">)</span>
<span class="n">upLeftPixel</span><span class="o">=</span><span class="n">firstMapArray</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">upLeftPixel</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Atlantic pixel RGB Value&#39;</span><span class="p">)</span>
<span class="n">atlanticPixel</span><span class="o">=</span><span class="n">firstMapArray</span><span class="p">[</span><span class="mi">450</span><span class="p">,</span><span class="mi">400</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">atlanticPixel</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;US pixel RGB Value&#39;</span><span class="p">)</span>
<span class="n">usPixel</span><span class="o">=</span><span class="n">firstMapArray</span><span class="p">[</span><span class="mi">150</span><span class="p">,</span><span class="mi">200</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">usPixel</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Russia pixel RGB Value&#39;</span><span class="p">)</span>
<span class="n">russiaPixel</span><span class="o">=</span><span class="n">firstMapArray</span><span class="p">[</span><span class="mi">80</span><span class="p">,</span><span class="mi">700</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">russiaPixel</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;North Africa pixel RGB Value&#39;</span><span class="p">)</span>
<span class="n">northAfricaPixel</span><span class="o">=</span><span class="n">firstMapArray</span><span class="p">[</span><span class="mi">180</span><span class="p">,</span><span class="mi">550</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">northAfricaPixel</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Upper left pixel RGB Value
[214 213 227]

Atlantic pixel RGB Value
[14 49 69]

US pixel RGB Value
[207 186 155]

Russia pixel RGB Value
[65 74 45]

North Africa pixel RGB Value
[204 170 125]
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="what-s-in-a-pixel">
<h2>What’s in a pixel?<a class="headerlink" href="#what-s-in-a-pixel" title="Permalink to this headline">¶</a></h2>
<p>In the code block above we have queried the entries for the specified pixels and obtained these results:</p>
<ul class="simple">
<li><p>[0,0], which is the upper leftmost pixel = [214 213 227]</p></li>
<li><p>[150,400], which is in the Atlantic = [14 49 69]</p></li>
<li><p>[150,250], which is in the middle of the United States = [207 186 155]</p></li>
<li><p>[80,700], which is in western Russia = [65 74 45]</p></li>
<li><p>[180,550], which is in north Africa = [204 170 125]</p></li>
</ul>
<p>Below the label description for each pixel is the numeric color value (between 0 and 255) for the red, green, and blue channels respectively.  A 0 would indicate no presence of the color, while a 255 would constitute the maximal presence of the color.</p>
<p>Thus, for each of these pixels we have obtained a 1 by 3 output, which corresponds to the RGB value for each pixel.</p>
<div class="section" id="use-the-sliders-below-to-enter-in-the-values-obtained-for-the-pixels-listed-above-in-order-to-identify-the-corresponding-colors">
<h3>Use the sliders below to enter in the values obtained for the pixels listed above in order to identify the corresponding colors<a class="headerlink" href="#use-the-sliders-below-to-enter-in-the-values-obtained-for-the-pixels-listed-above-in-order-to-identify-the-corresponding-colors" title="Permalink to this headline">¶</a></h3>
<p>(NOTE: you can also simply enter the number beside the slider, rather than dragging it, if you prefer.)</p>
</div>
<div class="section" id="what-colors-do-you-get-for-these-points">
<h3>What colors do you get for these points?<a class="headerlink" href="#what-colors-do-you-get-for-these-points" title="Permalink to this headline">¶</a></h3>
<p>Use the color sliders for RGB values from the code below to determine what color corresponds to the selected pixels.  This will help you interpret what the numbers are actually indicating for that pixel, and how changes in these values result in changes to the image.  You can use the satellite image adjacent to the color plot to get a sense of where the color might be occurring in the image.</p>
<ul class="simple">
<li><p>upper leftmost pixel   [214 213 227] : ?</p></li>
<li><p>Atlantic pixel            [14 49 69] : ?</p></li>
<li><p>middle of US pixel     [207 186 155] : ?</p></li>
<li><p>western Russia pixel      [65 74 45] : ?</p></li>
<li><p>north Africa pixel     [204 170 125] : ?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="k">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="k">import</span> <span class="n">IntSlider</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="k">import</span> <span class="n">FloatSlider</span>

<span class="c1">#create blank structure for giant pixel display</span>
<span class="n">bigPixel</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">300</span><span class="p">,</span><span class="mi">300</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

<span class="c1">#update the output plot</span>
<span class="k">def</span> <span class="nf">updatePlots</span><span class="p">(</span><span class="n">bigPixel</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">imshow</span><span class="p">(</span><span class="n">bigPixel</span><span class="p">)</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">firstMap</span><span class="p">))</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1">#update the big pixel data object</span>
<span class="k">def</span> <span class="nf">updateBigPixel</span><span class="p">(</span><span class="n">redVal</span><span class="p">,</span><span class="n">greenVal</span><span class="p">,</span><span class="n">blueVal</span><span class="p">):</span>
    <span class="n">bigPixel</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">]</span><span class="o">=</span><span class="n">redVal</span>
    <span class="n">bigPixel</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="n">greenVal</span>
    <span class="n">bigPixel</span><span class="p">[:,:,</span><span class="mi">2</span><span class="p">]</span><span class="o">=</span><span class="n">blueVal</span>
    <span class="n">updatePlots</span><span class="p">(</span><span class="n">bigPixel</span><span class="p">)</span>
    
<span class="c1"># create the interactive objects</span>
<span class="n">redVal</span><span class="o">=</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">255</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">greenVal</span><span class="o">=</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">49</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">255</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">blueVal</span><span class="o">=</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">69</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">255</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#establish interactivity</span>
<span class="n">interact</span><span class="p">(</span><span class="n">updateBigPixel</span><span class="p">,</span> <span class="n">redVal</span><span class="o">=</span><span class="n">redVal</span><span class="p">,</span><span class="n">greenVal</span><span class="o">=</span><span class="n">greenVal</span><span class="p">,</span><span class="n">blueVal</span><span class="o">=</span><span class="n">blueVal</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "5881bf9784e248b2811850d187735509", "version_major": 2, "version_minor": 0}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.updateBigPixel(redVal, greenVal, blueVal)&gt;
</pre></div>
</div>
</div>
</div>
<p>Ultimately, you should obtain the colors presented in the swatches below, which are the pixel colors plotted along several adjacent blocks.  Each color swatch corresponds to the color of the respective pixel.</p>
</div>
<div class="section" id="what-are-the-colors-for-these-pixels">
<h3>What are the colors for these pixels?<a class="headerlink" href="#what-are-the-colors-for-these-pixels" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>upper leftmost pixel:  ?</p></li>
<li><p>Atlantic pixel:  ?</p></li>
<li><p>(midwest) United States pixel :  ?</p></li>
<li><p>(western) Russia pixel:  ?</p></li>
<li><p>(north) Africa pixel:  ?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#create empty array</span>
<span class="n">colorArray</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colorArray</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">#begin painting the array, remember 0 indexing</span>
<span class="n">colorArray</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">99</span><span class="p">,:]</span><span class="o">=</span><span class="n">upLeftPixel</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">colorArray</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">:</span><span class="mi">199</span><span class="p">,:]</span><span class="o">=</span><span class="n">atlanticPixel</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">colorArray</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">:</span><span class="mi">299</span><span class="p">,:]</span><span class="o">=</span><span class="n">usPixel</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">colorArray</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span><span class="mi">300</span><span class="p">:</span><span class="mi">399</span><span class="p">,:]</span><span class="o">=</span><span class="n">russiaPixel</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">colorArray</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span><span class="mi">400</span><span class="p">:</span><span class="mi">500</span><span class="p">,:]</span><span class="o">=</span><span class="n">northAfricaPixel</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1">#plot the color sample</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">imshow</span><span class="p">(</span><span class="n">colorArray</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(100, 500, 3)
</pre></div>
</div>
<img alt="../_images/Intro_to_discretized_image_representation_&amp;_maps_11_1.png" src="../_images/Intro_to_discretized_image_representation_&amp;_maps_11_1.png" />
</div>
</div>
</div>
</div>
<div class="section" id="the-color-of-data">
<h2>The color of data<a class="headerlink" href="#the-color-of-data" title="Permalink to this headline">¶</a></h2>
<p>You should get approximately the following colors:</p>
<ul class="simple">
<li><p>upper leftmost pixel                  : Ice white</p></li>
<li><p>Atlantic pixel                        : Blue</p></li>
<li><p>middle of the United States pixel     : Light brown</p></li>
<li><p>western Russia pixel                  : Green</p></li>
<li><p>north Africa pixel                    : Yellow-orange</p></li>
</ul>
<p>Given that the example image we are using is of a geographic satellite map of the world, these colors correspond to the color (<a class="reference external" href="https://en.wikipedia.org/wiki/Reflectance">reflected visible light</a>) of the surface of the Earth in that precise location (As viewed from space, roughly speaking).  With this information (and our basic understanding of <a class="reference external" href="https://en.wikipedia.org/wiki/Ecology">Earth’s ecology</a> we can make educated guesses as to the types of environments (<a class="reference external" href="https://en.wikipedia.org/wiki/Biome">biomes</a>) associated with each of these locations using the color information.   Note that, in a very straightforward sense, we are using quantitative image data to make inferences about the object that was imaged.  In principle this is what we are endeavoring to do with medical and brain images as well.  Before we get to that though, let’s continue with our consideration of this image.</p>
<div class="section" id="what-types-of-environments-are-found-at-each-of-these-pixels">
<h3>What types of environments are found at each of these pixels?<a class="headerlink" href="#what-types-of-environments-are-found-at-each-of-these-pixels" title="Permalink to this headline">¶</a></h3>
<p>(feel free to leverage the location information provided with the label/description of the pixel’s source)</p>
<p>We’ll plot the subsection of the satellite image surrounding each pixel below, in order to provide you with a bit of <a class="reference external" href="https://en.wikipedia.org/wiki/Topography">topographic</a> context related to what the pixel represents.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#create empty array</span>
<span class="n">sectionArray</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">99</span><span class="p">,</span><span class="mi">499</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sectionArray</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">#remember the sources</span>
<span class="c1">#upLeftPixel=firstMapArray[0,0]</span>
<span class="c1">#atlanticPixel=firstMapArray[450,400]</span>
<span class="c1">#usPixel=firstMapArray[150,250]</span>
<span class="c1">#russiaPixel=firstMapArray[80,700]</span>
<span class="c1">#northAfricaPixel=firstMapArray[180,550]</span>

<span class="c1">#begin painting the array, remember 0 indexing, extracting 100x100 squares from original image</span>
<span class="n">sectionArray</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">99</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">99</span><span class="p">,:]</span><span class="o">=</span><span class="n">firstMapArray</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">99</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">99</span><span class="p">,:]</span>
<span class="n">sectionArray</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">99</span><span class="p">,</span><span class="mi">100</span><span class="p">:</span><span class="mi">199</span><span class="p">,:]</span><span class="o">=</span><span class="n">firstMapArray</span><span class="p">[</span><span class="mi">400</span><span class="p">:</span><span class="mi">499</span><span class="p">,</span><span class="mi">350</span><span class="p">:</span><span class="mi">449</span><span class="p">,:]</span>
<span class="n">sectionArray</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">99</span><span class="p">,</span><span class="mi">200</span><span class="p">:</span><span class="mi">299</span><span class="p">,:]</span><span class="o">=</span><span class="n">firstMapArray</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">199</span><span class="p">,</span><span class="mi">150</span><span class="p">:</span><span class="mi">249</span><span class="p">,:]</span>
<span class="n">sectionArray</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">99</span><span class="p">,</span><span class="mi">300</span><span class="p">:</span><span class="mi">399</span><span class="p">,:]</span><span class="o">=</span><span class="n">firstMapArray</span><span class="p">[</span><span class="mi">30</span><span class="p">:</span><span class="mi">129</span><span class="p">,</span><span class="mi">650</span><span class="p">:</span><span class="mi">749</span><span class="p">,:]</span>
<span class="n">sectionArray</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">99</span><span class="p">,</span><span class="mi">400</span><span class="p">:</span><span class="mi">499</span><span class="p">,:]</span><span class="o">=</span><span class="n">firstMapArray</span><span class="p">[</span><span class="mi">130</span><span class="p">:</span><span class="mi">229</span><span class="p">,</span><span class="mi">500</span><span class="p">:</span><span class="mi">599</span><span class="p">,:]</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">imshow</span><span class="p">(</span><span class="n">sectionArray</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(99, 499, 3)
</pre></div>
</div>
<img alt="../_images/Intro_to_discretized_image_representation_&amp;_maps_13_1.png" src="../_images/Intro_to_discretized_image_representation_&amp;_maps_13_1.png" />
</div>
</div>
</div>
</div>
<div class="section" id="a-biome-s-color">
<h2>A biome’s color<a class="headerlink" href="#a-biome-s-color" title="Permalink to this headline">¶</a></h2>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Label/Description</strong></p></th>
<th class="head"><p><strong>Color</strong></p></th>
<th class="head"><p><strong>Biome</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><em>upper leftmost pixel</em></p></td>
<td><p>White</p></td>
<td><p>Ice</p></td>
</tr>
<tr class="row-odd"><td><p><em>Atlantic</em></p></td>
<td><p>Blue</p></td>
<td><p>Ocean</p></td>
</tr>
<tr class="row-even"><td><p><em>middle of the United States</em></p></td>
<td><p>Yellow</p></td>
<td><p>Plains</p></td>
</tr>
<tr class="row-odd"><td><p><em>western Russia</em></p></td>
<td><p>Green</p></td>
<td><p>Forests</p></td>
</tr>
<tr class="row-even"><td><p><em>north Africa</em></p></td>
<td><p>Orange</p></td>
<td><p>Desert</p></td>
</tr>
</tbody>
</table>
<p>As we can see, it’s pretty straightforward to infer the environment type from the color of the pixel.  Keep in mind that, although we are abstracting from the visible color (a visible property resulting from the RGB value information represented) to a <a class="reference external" href="https://en.wikipedia.org/wiki/Color_term">color name</a> (a categorical label), we’ve essentially applied this environmental label in virtue of a quantitative property, specifically the RGB value.    This is a <em>very</em> interesting capability, particularly when we describe it a bit more generally:</p>
<p>We can <strong>systematically</strong> apply a <strong>categorical label</strong> using <strong>quantitative information</strong></p>
<div class="section" id="how-might-we-use-this-here-with-the-satellite-data">
<h3>How might we use this here with the satellite data?<a class="headerlink" href="#how-might-we-use-this-here-with-the-satellite-data" title="Permalink to this headline">¶</a></h3>
<p>Consider for a moment the sorts of things we could now do with the data from our satellite image.  How can we leverage this new capability?</p>
<p>One thing you might wonder is:</p>
</div>
<div class="section" id="can-we-select-all-of-the-pixels-that-correspond-to-a-specific-biome">
<h3>Can we select <em>all</em> of the pixels that correspond to a specific biome?<a class="headerlink" href="#can-we-select-all-of-the-pixels-that-correspond-to-a-specific-biome" title="Permalink to this headline">¶</a></h3>
<p>Well, yes.  Although some environment types exhibit some variability in their coloring (in that they exhibit a range of RGB color values), others are fairly homogeneous, and therefore easier to find systematically.  Broadly speaking though, this capability is very much within our grasp.</p>
</div>
<div class="section" id="which-environment-is-the-most-homogenous">
<h3>Which environment is the most homogenous?<a class="headerlink" href="#which-environment-is-the-most-homogenous" title="Permalink to this headline">¶</a></h3>
<p>If we wanted to demonstrate this, we would probably want to pick the easiest example biome to use.  In this case, “easy” would correspond to a biome which is (1) visually distinct from others, but fairly consistent within itself.  Which environment type would be characterized by the narrowest range of color values?</p>
</div>
<div class="section" id="how-would-create-a-rule-or-series-of-rules-i-e-an-algorithm-to-find-all-of-the-image-pixels-that-correspond-to-this-environment-type">
<h3>How would create a rule, or series of rules (i.e. an <a class="reference external" href="https://en.wikipedia.org/wiki/Algorithm"><em>algorithm</em></a>), to find all of the image pixels that correspond to this environment type?<a class="headerlink" href="#how-would-create-a-rule-or-series-of-rules-i-e-an-algorithm-to-find-all-of-the-image-pixels-that-correspond-to-this-environment-type" title="Permalink to this headline">¶</a></h3>
<p>Practically speaking though, how would you, based on the numerical RGB values, decide whether or not a specific pixel is of the specified environment type?</p>
</div>
<div class="section" id="a-potential-target">
<h3>A potential target?<a class="headerlink" href="#a-potential-target" title="Permalink to this headline">¶</a></h3>
<p>The ocean appears to be the most homogenous of the various environment types, and is quite distinct from the land based biomes.  As such, we’ll use it as our example target.</p>
</div>
<div class="section" id="how-can-we-find-all-pixels-of-that-type">
<h3><em>How</em> can we find all pixels of that type?<a class="headerlink" href="#how-can-we-find-all-pixels-of-that-type" title="Permalink to this headline">¶</a></h3>
<p>Well, before we can actually try to identify all of the ocean pixels, we first have to determine which data point–that is, which specific pixel–we will treat as <em>the</em> quintessential ocean color.  In essence, this should be the “average” ocean color, the middle-ground between all ocean pixels.  For our purposes here we can just stick with the color we selected for the Atlantic pixel.  However, we should keep in mind that this will also pick up fresh water bodies as well, as their color properties aren’t vastly different from the oceans (we can’t really detect fresh and salt water bodies using these methods).</p>
<p>Lets go ahead and set the color of that pixel (14 49 69) as a variable and then count how many pixels that <em>exact</em> color value corresponds to.</p>
<p>We’ll print out the number of candidate pixels below (i.e. the number of pixels in the image), along with the number that matched the variable we set.  Keep in mind that what we’re counting here are those pixels that are <em>exactly</em> that color.</p>
</div>
<div class="section" id="how-many-pixels-do-you-expect-this-to-be">
<h3>How many pixels do you expect this to be?<a class="headerlink" href="#how-many-pixels-do-you-expect-this-to-be" title="Permalink to this headline">¶</a></h3>
<p>We know that the ocean covers approximately <a class="reference external" href="https://www.usgs.gov/special-topic/water-science-school/science/how-much-water-there-earth">71 percent of the earth’s surface</a>.  How many pixels from the image do we expect this to correspond to if the total number of pixels in the image is 1000*500=500,000?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Atlantic pixel RGB&#39;</span><span class="p">)</span>
<span class="c1">#equitorial blue</span>
<span class="c1">#atlanticColor=firstMapArray[150,400]</span>

<span class="c1">#nonequator blue</span>
<span class="c1">#atlanticColor=firstMapArray[400,200]</span>

<span class="c1">#artic blue</span>
<span class="n">atlanticColor</span><span class="o">=</span><span class="n">firstMapArray</span><span class="p">[</span><span class="mi">450</span><span class="p">,</span><span class="mi">400</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">atlanticColor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="c1">#subtract atlantic blue from the pixel data.  0 values indicate equivalence</span>
<span class="n">zeroBlueMask</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">firstMapArray</span><span class="p">,</span><span class="n">atlanticColor</span><span class="p">)</span>
<span class="c1">#sum the total color difference, we use absolute to avoid strange edge cases where the distance from blue sums to 0</span>
<span class="n">blueDiffSum</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">zeroBlueMask</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1">#[Atlantic blue - Atlantic blue] = 0 , so the zeros we find indicate the exact matches</span>
<span class="c1">#anything else is a different color</span>
<span class="n">exactColorMask</span><span class="o">=</span><span class="p">[</span><span class="n">blueDiffSum</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>

<span class="c1">#counts the number of nonzero (not false) values in mask array</span>
<span class="n">totalExact</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">exactColorMask</span><span class="p">)</span>

<span class="c1">#extract the image dimensions from the image dimension variable obtained earlier</span>
<span class="n">imgDimY</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">firstMapShape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">imgDimX</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">firstMapShape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total number of pixels in satellite .jpeg image:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">([</span><span class="n">imgDimY</span><span class="o">*</span><span class="n">imgDimX</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of pixels EXACTLY equal to atlantic pixel color value:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">totalExact</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Proportion of total pixels:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">totalExact</span><span class="p">,[</span><span class="n">imgDimY</span><span class="o">*</span><span class="n">imgDimX</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Percentage of total pixels:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">totalExact</span><span class="p">,[</span><span class="n">imgDimY</span><span class="o">*</span><span class="n">imgDimX</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Atlantic pixel RGB
[14 49 69]

Total number of pixels in satellite .jpeg image:
[500000]

Number of pixels EXACTLY equal to atlantic pixel color value:
1031

Proportion of total pixels:
[0.002062]

Percentage of total pixels:
[0.2062]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="an-unexpected-result">
<h3>An unexpected result?<a class="headerlink" href="#an-unexpected-result" title="Permalink to this headline">¶</a></h3>
<p>First thing to note: 1031 pixels is a relatively small proportion of 500,000.  If the Earth’s surface is 71% water, why didn’t we get anything remotely close to that with our previous result?  We didn’t even get 1%!</p>
<div class="section" id="a-possible-explanation">
<h4>A possible explanation?<a class="headerlink" href="#a-possible-explanation" title="Permalink to this headline">¶</a></h4>
<p>One thing to consider is that there are a lot of different combinations of colors that could represent water.  Indeed, there’s a decent amount of variability visible in the initial satellite image–it’s not just one color, even in the ocean.  Given how we were counting pixels, if a value was off by even one unit (for any of the color channels!), it wouldn’t have been counted above.  This explains how we only got about .2 % of the surface pixels–only .2% of the pixels on the map <em>exactly</em> match the pixel we chose.</p>
</div>
<div class="section" id="so-how-do-we-find-the-remaining-70-8-of-pixels">
<h4>So how do we find the remaining 70.8% of pixels?<a class="headerlink" href="#so-how-do-we-find-the-remaining-70-8-of-pixels" title="Permalink to this headline">¶</a></h4>
<p>Our “naive”, quantitative method for finding pixels that were the exact same as “Atlantic blue” provides a big hint as to how we could achieve this.</p>
</div>
<div class="section" id="how-did-we-count-the-number-of-atlantic-blue-pixels">
<h4>How did we count the number of “Atlantic blue” pixels?<a class="headerlink" href="#how-did-we-count-the-number-of-atlantic-blue-pixels" title="Permalink to this headline">¶</a></h4>
<p>(look back at the preceding code block and inspect the commented code to see how the “search” (for matches) and count was implemented)</p>
</div>
</div>
<div class="section" id="checking-our-math">
<h3>Checking our math<a class="headerlink" href="#checking-our-math" title="Permalink to this headline">¶</a></h3>
<p>Our total count was reported by printing the contents of the <strong>totalExact</strong> variable.  This variable, in turn, was computed by counting the number of non-zero entries in the <strong>exactColorMask</strong> variable.  What was stored in the <strong>exactColorMask</strong> variable and how was it generated?</p>
<p><strong>exactColorMask</strong> was generated by subtracting the “Atlantic blue” RGB value [14 49 69] from <em>each</em> pixel in the original image and then (after summing the absolute value of this difference across all three color channels) looking for pixels which had <strong>no</strong> difference (i.e. were <strong>exactly</strong> 0).</p>
<p>Thus in pixels that were <em>precisely</em> “Atlantic blue” we had  the following computational/mathematical situation:</p>
<p>[Atlantic blue]-[Atlantic blue] == [14 49 69] - [14 49 69] = [0 0 0]</p>
<p>and subsequently,</p>
<p>sum([0,0,0])=0</p>
<p>There is no difference in any of the RGB channels in this specific case, when the color of the pixel is <em>exactly</em> “Atlantic blue”.  As such, we were able to sum across the third dimension (the color channel dimension) and thereby find the pixels without <em>any</em> difference.  Keep in mind that, although the colors represented by [14 49 70] and [14 50 69] may not be distinguishable by our eyes, this method would return a nonzero value in the second case.  For our exact match-based algorithm (because it is an algorithm, just a simple one) this would be enough to indicate a difference.  In an “off-by-one” case like this our algorithm would not include that pixel in our count of “Atlantic blue” pixels.  How can we add a bit of wiggle room to this?</p>
<div class="section" id="how-can-we-include-pixel-colors-that-are-nearby-atlantic-blue-14-49-69-in-our-count">
<h4>How can we include pixel colors that are “nearby” Atlantic blue [14 49 69] in our count?<a class="headerlink" href="#how-can-we-include-pixel-colors-that-are-nearby-atlantic-blue-14-49-69-in-our-count" title="Permalink to this headline">¶</a></h4>
<p>Our “exact-match” method seems a bit harsh.  Do we really need to throw out color values that are “close” to our “Atlantic blue” color?  Is there a way we could include pixel colors like [14 49 70] or [14 48 69] in our count of water pixels?</p>
<p>Well, the answer to these questions depends on our ability to systematically define (i.e. <a class="reference external" href="https://en.wikipedia.org/wiki/Operationalization">operationalize</a>) the notion of “close” we are referring to here.</p>
</div>
<div class="section" id="how-can-we-define-close-in-a-math-like-way">
<h4>How can we define “close” in a math-like way?<a class="headerlink" href="#how-can-we-define-close-in-a-math-like-way" title="Permalink to this headline">¶</a></h4>
</div>
</div>
</div>
<div class="section" id="using-trigonometry-to-compute-color-distances">
<h2>Using trigonometry to compute color distances<a class="headerlink" href="#using-trigonometry-to-compute-color-distances" title="Permalink to this headline">¶</a></h2>
<p>When we ran the “Atlantic blue” algorithm described above, we essentially treated the output as binarized.  What is meant by this (“binarized”) is that the answer to our question (“Is this Atlantic blue”) was either <strong>Yes</strong> or <strong>No</strong>–there was no middle ground to the potential answers to this question.  There wasn’t an option for “sort of”.  The <em>only</em> case in which the answer wasn’t <strong>No</strong>  was when the “difference” between “Atlantic blue” and the pixel in question was exactly zero, in which case the answer was <strong>Yes</strong>.  To rephrase this question as a <a class="reference external" href="https://en.wikipedia.org/wiki/Pseudocode">pseudo-code</a> <a class="reference external" href="https://en.wikipedia.org/wiki/Boolean_expression">if statement</a>:</p>
<p>“Is this Atlantic blue” –&gt; if “Atlantic blue”-currentPixel==0, <strong>yes</strong>, otherwise <strong>no</strong></p>
<p>However, keen eyes will note that the most direct output of our method (the initial subtraction result, stored in the variable <strong>zeroBlueMask</strong>) <em>is not</em> actually binarized.  That is, we don’t <em>actually</em> get only “yes” or “no” answers from the difference computation. Instead, we apply an additional computation to the <strong>zeroBlueMask</strong> (and store the results in <strong>blueDiffSum</strong> and <strong>exactColorMask</strong>) and then convert our answer to a binarized output.</p>
<p>**Is there something in the zeroBlueMask variable that we can make use of to determine “close” colors?”</p>
<div class="section" id="what-do-we-actually-get-from-zerobluemask-np-subtract-firstmaparray-atlanticcolor">
<h3>What do we actually get from “zeroBlueMask=np.subtract(firstMapArray,atlanticColor)”<a class="headerlink" href="#what-do-we-actually-get-from-zerobluemask-np-subtract-firstmaparray-atlanticcolor" title="Permalink to this headline">¶</a></h3>
<p>Instead of storing 1 or 0 (binary “Yes/TRUE” or “No/False”), for each pixel, the contents of <strong>zeroBlueMask</strong> are a 1x3 vector that corresponds to the mathematical difference between the RGB values for “Atlantic blue” and the RGB values for the relevant pixel.  When all of these differences are stored in the same arrangement as the original image, we get a very familiar output when we check the dimensions of this structure (<strong>zeroBlueMask</strong>) because we have computed this value for each pixel.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dimensions of zeroBlueMask variable:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">zeroBlueMask</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dimensions of zeroBlueMask variable:
(500, 1000, 3)
</pre></div>
</div>
</div>
</div>
<p>In 1031 cases (i.e. for 1031 pixels) the difference between the “Atlantic blue” value [14 49 69] is [0 0 0]–zero for each color channel. However, for [14 49 70] it would be [0 0 1] and for [14 48 69] it would be [0 -1 0].</p>
<p>We can think about those colors as being “1” away from “Atlantic blue”.  How many pixels are “off-by-one” like this?  To check this, we would need to look at the <strong>blueDiffSum</strong> variable, which has summed the cross-channel differences into a single value.  In this 2 dimensional structure, we would be looking for values equal to 1.</p>
<p>NOTE: in the code block below, you’ll note that the variable <strong>offByValue</strong> is set to 2.  This is despite our immediately preceding discussion focusing on pixels that were “off-by-one”.  The reason for this discrepancy is that, as it turns out, there are no pixel values that are <em>just</em> one numerical value off from the “Atlantic blue” value we are looking for.  As such, in order to find <em>any</em> additional pixels, we have to increase this “off-by” number (below represented by the <strong>offByValue</strong> variable) to 2.  The likely cause of this is a phenomenon known as <a class="reference external" href="https://en.wikipedia.org/wiki/JPEG#JPEG_compression">JPEG compression</a> which is a specialized process used by image handling &amp; processing programs which attempts to “shrink” the storage size of the image by algorithmically recoloring nearby pixels.  Feel free to modify the <strong>offByValue</strong> to demonstrate this for yourself.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dimensions of blueDiffSum variable:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">blueDiffSum</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="c1">#here we set the offByValue</span>
<span class="c1">#feel free to play with this value </span>
<span class="n">offByValue</span><span class="o">=</span><span class="mi">2</span>

<span class="c1">#here we modify a computation we used earlier.  Before we were looking for blueDiffSum==0</span>
<span class="c1">#now we are looking for the value specified by offByValue</span>
<span class="n">offBySomeColorMask</span><span class="o">=</span><span class="p">[</span><span class="n">blueDiffSum</span><span class="o">==</span><span class="n">offByValue</span><span class="p">]</span>

<span class="c1">#counts the number of nonzero (not false) values in off-by-some mask array</span>
<span class="n">totalOffBySome</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">offBySomeColorMask</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of pixels off by a few from atlantic pixel color value:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">totalOffBySome</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Proportion of total pixels off-by-some:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">totalOffBySome</span><span class="p">,[</span><span class="n">imgDimY</span><span class="o">*</span><span class="n">imgDimX</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Percentage of total pixels off-by-some:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">totalOffBySome</span><span class="p">,[</span><span class="n">imgDimY</span><span class="o">*</span><span class="n">imgDimX</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dimensions of blueDiffSum variable:
(500, 1000)

Number of pixels off by a few from atlantic pixel color value:
86

Proportion of total pixels off-by-some:
[0.000172]

Percentage of total pixels off-by-some:
[0.0172]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="a-rough-first-step">
<h3>A rough first step<a class="headerlink" href="#a-rough-first-step" title="Permalink to this headline">¶</a></h3>
<p>In the above code block, we counted how many pixels were off by some small amount (default=2) from the “Atlantic blue” color value.  Note that, algorithmically speaking, we were kind of doing this in a rough fashion:  we were simply summing the differences from the specified RGB values across all dimensions.  This was not a particularly sophisticated method and it treats some distance scenarios (i.e. [1 1 1] and [0 0 3]) as the exact same, even though these are “different kinds of differences”.  That being said, it does hint at a structured framework for considering these color differences.</p>
</div>
<div class="section" id="can-we-generalize-this-concept">
<h3>Can we generalize this concept?<a class="headerlink" href="#can-we-generalize-this-concept" title="Permalink to this headline">¶</a></h3>
<p>If we think about this a bit more geometrically, we could treat the RGB values as the axes of an XYZ plot.  In such a fashion, each color could be placed in this arrangement in accordance with their X (red), Y (green), and Z (blue) coordinates.  Colors could then have their “distance” computed by seeing how far away they are from one another in this spatial arrangement.  In this way we would be computing the <a class="reference external" href="https://en.wikipedia.org/wiki/Hypotenuse"><em>hypotenuse</em></a> formed by the 3 dimensional right triangle manifested by the differences in color values.  The formula would look roughly like this</p>
<p>“Color Hypotenuse Distance”=<span class="math notranslate nohighlight">\(\sqrt{(R^2 +G^2 + B^2 )}\)</span></p>
<p>where</p>
<p>R=”Red Difference”=RedVal1-RedVal2<br />
G=”Green Difference”=GreenVal1-GreenVal2<br />
B=”Blue Difference”=BlueVal1-BlueVal2</p>
<p>This constitutes a good method we can systematically use to compute pixels’ color distance from “Atlantic blue”!  Indeed, this is a <a class="reference external" href="https://en.wikipedia.org/wiki/Color_difference">fairly well established method</a> for making this sort of assessment.</p>
<p>Let’s implement some code that does exactly this.  Next, we’ll apply that code to compute the color distance from the “Atlantic blue” value.  After that, we will then plot a <a class="reference external" href="https://en.wikipedia.org/wiki/Histogram">histogram</a> of these differences to get a sense of the distribution of color distances from “Atlantic blue” in the image.  Finally we’ll also look at these distances mapped on to the original satellite image to get a sense of where these differences (and similarities) are occuring.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1">#quick and dirty general use hypotenuse algorithm, can be used for 2d or 3D</span>
<span class="k">def</span> <span class="nf">multiDHypot</span><span class="p">(</span><span class="n">coords1</span><span class="p">,</span><span class="n">coords2</span><span class="p">):</span>
    <span class="n">dimDisplace</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">coords1</span><span class="p">,</span><span class="n">coords2</span><span class="p">)</span>
    <span class="n">elementNum</span><span class="o">=</span><span class="n">dimDisplace</span><span class="o">.</span><span class="n">size</span>
    <span class="n">elementSquare</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">dimDisplace</span><span class="p">)</span>
    <span class="n">elementSquareSum</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">elementSquare</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">elementNum</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">hypotLeng</span><span class="o">=</span><span class="n">dimDisplace</span>
    <span class="k">elif</span> <span class="n">elementNum</span><span class="o">==</span><span class="mi">2</span><span class="p">:</span>
        <span class="n">hypotLeng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">elementSquareSum</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">elementNum</span><span class="o">==</span><span class="mi">3</span><span class="p">:</span>
        <span class="n">hypotLeng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">elementSquareSum</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">hypotLeng</span>

<span class="c1">#initialize distance storage structure</span>
<span class="n">colorDistMeasures</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(([</span><span class="n">firstMapShape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">firstMapShape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>

<span class="c1">#iteratively apply the distance computation</span>
<span class="k">for</span> <span class="n">iRows</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">firstMapShape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">iColumns</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">firstMapShape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="c1">#extract the current pixel</span>
        <span class="n">curPixelVal</span><span class="o">=</span><span class="n">zeroBlueMask</span><span class="p">[</span><span class="n">iRows</span><span class="p">,</span><span class="n">iColumns</span><span class="p">]</span>
        
        <span class="c1">#compute the color distance for this pixel, and store it in the corresponding spot</span>
        <span class="c1">#in colorDistMeasures, use this if your input above was firstMapArray</span>
        <span class="c1">#Sidenote:  This may require additional code modifications</span>
        <span class="c1">#colorDistMeasures[iRows,iColumns]=multiDHypot(curPixelVal,atlanticColor)</span>
    
        <span class="c1">#compute the color distance for this pixel, and store it in the corresponding stpot</span>
        <span class="c1">#in colorDistMeasures, use this if your input above was zeroBlueMask</span>
        <span class="c1">#we use [0 0 0 ] as our input because zeroBlueMask has already had the atlantic blue</span>
        <span class="c1">#subtracted from it</span>
        <span class="n">colorDistMeasures</span><span class="p">[</span><span class="n">iRows</span><span class="p">,</span><span class="n">iColumns</span><span class="p">]</span><span class="o">=</span><span class="n">multiDHypot</span><span class="p">(</span><span class="n">curPixelVal</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1">#data structure formatting for plotting</span>
<span class="n">flattenedDistances</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">colorDistMeasures</span><span class="p">)</span>

<span class="c1">#plotting code for histogram</span>
<span class="n">ax1</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1">#NOTE: To get a visual sense of the aforementioned JPEG color compression, set bins = 500 </span>
<span class="c1">#in the next line.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">flattenedDistances</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Distance from ocean color&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Number of pixels&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of RGB color distance from Atlantic blue color&#39;</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mf">18.5</span><span class="p">,</span> <span class="mf">10.5</span><span class="p">)</span>

<span class="c1">#plotting code for geography plot</span>
<span class="n">ax2</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">heatPlot</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">colorDistMeasures</span><span class="p">)</span>
<span class="n">fig2</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig2</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">heatPlot</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.colorbar.Colorbar at 0x11532f550&gt;
</pre></div>
</div>
<img alt="../_images/Intro_to_discretized_image_representation_&amp;_maps_25_1.png" src="../_images/Intro_to_discretized_image_representation_&amp;_maps_25_1.png" />
</div>
</div>
</div>
</div>
<div class="section" id="visualizing-color-distances">
<h2>Visualizing color distances<a class="headerlink" href="#visualizing-color-distances" title="Permalink to this headline">¶</a></h2>
<p>Above are the two plots that are generated by the preceding code.  The first of these plots the distribution of color distances from “Atlantic blue” found in the satellite image.  The X axis corresponds to the “color distance” from “Atlantic blue” while the Y axis corresponds to the number of pixels whose color is the relevant distance away from “Atlantic blue”.  Thus, in total, the various bars of this graph should collectively represent distance calculations from all 500 x 1000 = 500,000 pixels.  From this same histogram plot we can also see that there appear to be three or four partially overlapping “clusters”:</p>
<ul class="simple">
<li><p>0    to  ~75</p></li>
<li><p>~100  to  ~230</p></li>
<li><p>~230  to  ~290</p></li>
<li><p>~300  to  ~340</p></li>
</ul>
<p>These likely correspond to colors/environment-types that cover large portions of the Earth.</p>
<div class="section" id="the-big-cluster-from-0-to-75-is-the-one-we-are-interested-in-and-to-see-why-we-can-look-at-the-plot-below-the-histogram">
<h3>The big cluster, from 0 to 75 is the one we are interested in, and to see why we can look at the plot below the histogram.<a class="headerlink" href="#the-big-cluster-from-0-to-75-is-the-one-we-are-interested-in-and-to-see-why-we-can-look-at-the-plot-below-the-histogram" title="Permalink to this headline">¶</a></h3>
<p>In the plot below the histogram we see a differently colored view of the satellite image.  Here, instead of visible light, we are plotting the numerical <a class="reference external" href="https://en.wikipedia.org/wiki/Color_difference">color distance</a> from “Atlantic blue”.  Referencing the colorbar to the right, we see that most of the ocean is less than 100 “distance units” from the “Atlantic blue” color (coincidentally depicted in blue with this color mapping).</p>
<p>What if we selected only those pixels that were <em>less than</em> some specified distance (e.g. 75 or 100) from “Atlantic blue”?</p>
</div>
<div class="section" id="what-s-the-ideal-distance-from-atlantic-blue-to-capture-as-many-water-pixels-as-possible-and-as-few-land-pixels-as-possible">
<h3>What’s the ideal distance from “Atlantic blue” to capture as many water pixels as possible and as few land pixels as possible?<a class="headerlink" href="#what-s-the-ideal-distance-from-atlantic-blue-to-capture-as-many-water-pixels-as-possible-and-as-few-land-pixels-as-possible" title="Permalink to this headline">¶</a></h3>
<p>Below we’ll establish a threshold value for selecting the pixels of interest.  Use the slider bar to move the threshold along the histogram.  Pixels that are <em>less than</em> the specified color distance from “Atlantic blue” will be displayed in <strong>yellow</strong>, while those that are <em>greater than</em> the specified color distance will be displayed in <strong>blue-purple</strong>.  Your goal is to select the ideal threshold value that best (and most selectively) finds water pixels.  There are multiple ways to manipulate the slider:  You can use your mouse directly, you can use the arrow keys of your keyboard, or you can enter a number directly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="k">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="k">import</span> <span class="n">IntSlider</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="k">import</span> <span class="n">FloatSlider</span>

<span class="c1">#function for modifying the plot via the input cutVal</span>
<span class="k">def</span> <span class="nf">updatePlots</span><span class="p">(</span><span class="n">DistanceArray</span><span class="p">,</span><span class="n">cutVal</span><span class="p">):</span>

    <span class="c1">#modify input data structure</span>
    <span class="n">flattenedDistances</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">DistanceArray</span><span class="p">)</span>
    
    <span class="c1">#set plot features for histogram with cutVal line</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">flattenedDistances</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Distance from ocean color&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Number of pixels&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of RGB color distance from Atlantic pixel color&#39;</span><span class="p">)</span>
    <span class="n">xposition</span> <span class="o">=</span> <span class="p">[</span><span class="n">cutVal</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">xc</span> <span class="ow">in</span> <span class="n">xposition</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">xc</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
     
    <span class="c1">#compute binarized mask for values below cutVal</span>
    <span class="n">naiveOceanMask</span><span class="o">=</span><span class="n">DistanceArray</span><span class="o">&lt;</span><span class="n">cutVal</span>
    
    <span class="c1">#plot the image that results</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">imshow</span><span class="p">(</span><span class="n">naiveOceanMask</span><span class="p">)</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    
    <span class="c1"># Pie chart, where the slices will be ordered and plotted counter-clockwise:</span>
    <span class="n">maskLabels</span> <span class="o">=</span> <span class="s1">&#39;Presumed water&#39;</span><span class="p">,</span> <span class="s1">&#39;Presumed land&#39;</span>
    <span class="n">maskSizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">naiveOceanMask</span><span class="o">==</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">naiveOceanMask</span><span class="o">==</span><span class="mi">0</span><span class="p">)]</span>
    <span class="c1">#implement pie chart plot here</span>

<span class="c1">#create the function to manipulate</span>
<span class="k">def</span> <span class="nf">updateCut</span><span class="p">(</span><span class="n">cutVal</span><span class="p">):</span>
    <span class="n">updatePlots</span><span class="p">(</span><span class="n">colorDistMeasures</span><span class="p">,</span><span class="n">cutVal</span><span class="p">)</span>

<span class="c1">#establish the cutVal variable</span>
<span class="n">cutVal</span><span class="o">=</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">flattenedDistances</span><span class="p">),</span> <span class="nb">max</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">flattenedDistances</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#establish interactivity</span>
<span class="n">interact</span><span class="p">(</span><span class="n">updateCut</span><span class="p">,</span> <span class="n">cutVal</span><span class="o">=</span><span class="n">cutVal</span> <span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "42a53eb76cfb40ddbcb35248c5b03030", "version_major": 2, "version_minor": 0}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.updateCut(cutVal)&gt;
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="making-an-ocean-mask">
<h2>Making an ocean mask<a class="headerlink" href="#making-an-ocean-mask" title="Permalink to this headline">¶</a></h2>
<p>Above, you’ve used the slider bar to try and select a <a class="reference external" href="https://en.wikipedia.org/wiki/Color_difference">color distance</a> value which isolates just the water pixels.  The histogram plot is the same as the one from the previous cell, however the red bar indicates where in the distribution your current threshold is.  The second plot is the (binary) “mask” that you’ve created, in which <strong>yellow</strong> pixels indicate all of those pixels whose color distance is <strong>less</strong> than the threshold value you’ve set and the <strong>purple-blue</strong> pixels indicate all of those pixels whose color distance is <strong>greater</strong> than the threshold value you’ve set.  In this way, the yellow pixels represent those pixels that you deem sufficiently close to “Atlantic blue”, while the purple-blue ones are deemed too far from “Atlantic blue” to plausibly be considered water pixels.</p>
<div class="section" id="what-is-the-ideal-threshold-value">
<h3>What is the ideal threshold value?<a class="headerlink" href="#what-is-the-ideal-threshold-value" title="Permalink to this headline">¶</a></h3>
<p>Additionally, as you move the threshold around (beyond what would be needed to make an ocean mask), you can observe which portions of the map go from blue to yellow, and thereby get a sense of what the clusters might represent.</p>
</div>
<div class="section" id="what-might-the-histogram-clusters-correspond-to">
<h3>What might the histogram clusters correspond to?<a class="headerlink" href="#what-might-the-histogram-clusters-correspond-to" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="some-good-guesses-as-to-what-the-clusters-correspond-to">
<h3>Some good guesses as to what the clusters correspond to:<a class="headerlink" href="#some-good-guesses-as-to-what-the-clusters-correspond-to" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>0    to  ~75    = water</p></li>
<li><p>~100  to  ~230   = grasslands, lighter forests</p></li>
<li><p>~230  to  ~290   = mountains, darker forests, &amp; deserts</p></li>
<li><p>~300  to  ~340   = ice</p></li>
</ul>
</div>
<div class="section" id="a-good-guess-as-to-the-best-threshold-value">
<h3>A good guess as to the best threshold value<a class="headerlink" href="#a-good-guess-as-to-the-best-threshold-value" title="Permalink to this headline">¶</a></h3>
<p>A value between 63 and 80 seems to do well for selecting water, see which one you feel works best.</p>
<p>In this lesson we practiced with the creation of a mask using a threshold value on our image.  In the next lesson, we’ll try and compare the mask we generated to a preexisting mask of the planet’s water.  What we’ll learn is that, before the comparison can even be made, a bit of adjustment needs to be made, in order to ensure correspondence between the two images.  This will prove to be a very important insight, as this process of ensuring correspondence between two images is central to digital investigations of brain anatomy.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="Building_Bridges.html" title="previous page">Building bridges from the familiar to the unfamiliar</a>
    <a class='right-next' id="next-link" href="Aligning_two_images.html" title="next page">Aligning two images</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Daniel Bullock<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>