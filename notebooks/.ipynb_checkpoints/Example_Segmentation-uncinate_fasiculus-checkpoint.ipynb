{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Segmentation: uncinate fasiculus\n",
    "\n",
    "NOTE:  This segmentation is taken almost verbatim from a [recent version of a matlab-based WMA segmentation](https://github.com/DanNBullock/wma_tools/blob/53a4d99b68b832257c55d5f1320dc7266cc8c270/Segmentations/bsc_segmentAntPostTracts_v4.m#L76)\n",
    "\n",
    "## Beginning with practical considerations and limitations\n",
    "\n",
    "Before truly beginning the segmentation of the uncinate fasiculus, there's some setup that we need to do.  Among these steps are the loading of the relevant atlas and candidate tractome(s).  Astute observers may note that the loading process we use here is decidedly more... convoluted than normal.  This is due to the use of a workaround related to github's limitation of a 100 MB file size limit.  As such we'll be loading up 4 sub tractomes--divided up by streamline length--and then combine them into one.  As a further note, traditionally when we segment we want to have a very rich tractome to segment from so that are segmented tracts can be as full as possible.  In this case though, we are somewhat constrained by our medium, and so the tracts that segment will be significantly less full than they would typically be. One additional considertation to keep in mind is the length of the target tract.  \n",
    "\n",
    "Traditional tractography generation methods have a very low minimum streamline lenght (e.g. 10 mm).  Due to the stocastic nature of streamline generation, it is more likley to generate small streamlines than it is to generate long ones, because each additional node increases the probability that the node is \"not viable\" and thus the streamline fails to complete the generation process (an example of a [conjunct probability](https://en.wikipedia.org/wiki/Conditional_probability)).  However, we aren't looking for just any streamline, we are looking for a streamline which could be a member of the uncinate fasiculus.  As such, we know the general range of streamlines we would be looking for (~40 to 100 mm).  This is something to keep in mind when generating one's candidate tractome:  **in most cases, for major white matter tracts, shorter streamlines will not contribute to better segmentation outcomes**.  Instead, they will simply add to the file size of the tractogram and increase computation time.\n",
    "\n",
    "Lets move to this piecewise loading process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code ensures that we can navigate the WiMSE repo across multiple systems\n",
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "#get top directory path of the current git repository, under the presumption that \n",
    "#the notebook was launched from within the repo directory\n",
    "gitRepoPath=subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode('ascii').strip()\n",
    "\n",
    "#establish path to the \n",
    "wma_toolsDirPath=os.path.join(gitRepoPath,'wma_pyTools')   \n",
    "\n",
    "#change to the wma_tools path, load the function set, then change back to the top directory\n",
    "os.chdir(wma_toolsDirPath)\n",
    "import WMA_pyFuncs\n",
    "os.chdir(gitRepoPath)\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "grossAnatomyPath=os.path.join(gitRepoPath,'exampleData','GrossAnatomyLookup.csv')\n",
    "\n",
    "grossAnatTable=pd.read_csv(grossAnatomyPath)\n",
    "#load the atlas\n",
    "atlasPath=os.path.join(gitRepoPath,'exampleData','parc.nii.gz')\n",
    "#load it as an object\n",
    "atlasImg = nib.load(atlasPath)\n",
    "\n",
    "#get and copy the data\n",
    "relabeledAtlas=atlasImg.get_fdata().copy()\n",
    "\n",
    "#get the labels to iterate over\n",
    "uniqueAtlasEntries=np.unique(atlasImg.get_fdata()).astype(int)\n",
    "\n",
    "grossAnatList=grossAnatTable['GrossAnat'].unique()\n",
    "\n",
    "#iterate across unique label entries\n",
    "for iLabels in range(len(uniqueAtlasEntries)):\n",
    "    #print(np.isin(grossAnatTable['GrossAnat'].loc[grossAnatTable['#No.']==uniqueAtlasEntries[iLabels]],grossAnatList))\n",
    "    #replace the current uniqueAtlasEntries value with the label corresponding to the gross anat category\n",
    "    currentLabelReNum=np.where(np.isin(grossAnatList,grossAnatTable['GrossAnat'].loc[grossAnatTable['#No.']==uniqueAtlasEntries[iLabels]]))\n",
    "    relabeledAtlas[relabeledAtlas==uniqueAtlasEntries[iLabels]]=currentLabelReNum[0]\n",
    "\n",
    "grossAnatNifti=nib.Nifti1Image(relabeledAtlas, atlasImg.affine, atlasImg.header)  \n",
    "\n",
    "# load the tractography file into the streamsObjIN variable\n",
    "#smallTractogramPath=os.path.join(gitRepoPath,'exampleData','smallTractogram.tck')\n",
    "TractogramPath1='/Users/plab/Downloads/30to50mmtrack.tck'\n",
    "TractogramPath2='/Users/plab/Downloads/50to70mmtrack.tck'\n",
    "TractogramPath3='/Users/plab/Downloads/70to100mmtrack.tck'\n",
    "\n",
    "streamsObjIN1=nib.streamlines.load(TractogramPath1)\n",
    "streamsObjIN2=nib.streamlines.load(TractogramPath2)\n",
    "streamsObjIN3=nib.streamlines.load(TractogramPath3)\n",
    "\n",
    "#get tractogram from the Tck holder\n",
    "allStreams=np.concatenate((streamsObjIN1.streamlines[:],streamsObjIN2.streamlines[:],streamsObjIN3.streamlines[:]))\n",
    "\n",
    "sourceTractogram= nib.streamlines.tractogram.Tractogram(streamlines=allStreams,  affine_to_rasmm=streamsObjIN1.header['voxel_to_rasmm'])\n",
    "\n",
    "\n",
    "from dipy.tracking import utils\n",
    "#segment tractome into connectivity matrix from parcellation\n",
    "M, grouping=utils.connectivity_matrix(sourceTractogram.streamlines, grossAnatNifti.affine, \\\n",
    "                        label_volume=grossAnatNifti.get_fdata().astype(int), \n",
    "                        return_mapping=True,\n",
    "                        mapping_as_streamlines=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing the category\n",
    "\n",
    "The Uncinate is definitionally a fronto-temporal tract.  Althgouth we can be more specific than this, and note that it connecs the anteror temporal poles, we needn't actually be this specific, for the purposes of applying a categorical segmentation.  Instead, we can simply use the existing fronto-temporal category.\n",
    "\n",
    "Below, we'll visualize the relevant category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d5a614ca1543bf8f97068feb1dba34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='region1', index=9, options=(('unknown', 0), ('wm', 1), ('ventricle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.updateFunction(regionIndex1, regionIndex2)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#quick and dirty tractogram subsetter by Brad Caron\n",
    "#https://github.com/bacaron\n",
    "def extractSubTractogram(sourceTractogram,indexes):\n",
    "    #import relevant package\n",
    "    import nibabel as nib\n",
    "    #extrect the desired streamlines into a new streamline object\n",
    "    streamlines = sourceTractogram.streamlines[indexes]\n",
    "    #establish tractogram object\n",
    "    out_tractogram = nib.streamlines.tractogram.Tractogram(streamlines)\n",
    "    #adjust the relevant header fields\n",
    "    #don't bother for now, header is only relevant to Tck file\n",
    "    #for headerFields in ['total_count','count','nb_streamlines']:\n",
    "        #nb_streamlines is an int, whereas the others are strings, for some reason\n",
    "    #    if headerFields == 'nb_streamlines':\n",
    "    #        out_tractogram.header[headerFields] = len(streamlines)\n",
    "    #    else:\n",
    "    #        out_tractogram.header[headerFields] = '%s' %len(streamlines)\n",
    "    return out_tractogram\n",
    "\n",
    "#interactive plotting via niwidgets?  \n",
    "#widget within a widget doesn't seem to work\n",
    "def plotParcellationConnectionWidget(subTractogram):\n",
    "    #import widget\n",
    "    from niwidgets import StreamlineWidget\n",
    "    #set widget object\n",
    "    \n",
    "    sw = StreamlineWidget(streamlines=subTractogram)\n",
    "    #set plotting characteristics\n",
    "    style = {'axes': {'color': 'red',\n",
    "                  'label': {'color': 'white'},\n",
    "                  'ticklabel': {'color': 'white'},\n",
    "                  'visible': False},\n",
    "         'background-color': 'black',\n",
    "         'box': {'visible': False}}\n",
    "    #plot it\n",
    "    sw.plot(display_fraction=1, width=1000, height=1000, style=style, percentile=0)\n",
    "\n",
    "def plotTract(tractIn):\n",
    "    import numpy as np\n",
    "    from dipy.viz import window, actor\n",
    "    renderer = window.Scene()\n",
    "    stream_actor = actor.line(tractIn)\n",
    "    #renderer.set_camera(position=(-176.42, 118.52, 128.20),\n",
    "    #               focal_point=(113.30, 128.31, 76.56),\n",
    "    #                view_up=(0.18, 0.00, 0.98))\n",
    "    %matplotlib inline\n",
    "    renderer.add(stream_actor)\n",
    "    \n",
    "    window.show(renderer, size=(600, 600), reset_camera=True)\n",
    "\n",
    "def updateFunction(regionIndex1,regionIndex2):\n",
    "    currentRenumberIndex1=regionIndex1    \n",
    "    currentRenumberIndex2=regionIndex2   \n",
    " \n",
    "    \n",
    "    #check to make sure this pairing is actually in the connections\n",
    "    if np.logical_or((currentRenumberIndex1,currentRenumberIndex2) in grouping.keys(),(currentRenumberIndex1,currentRenumberIndex2) in grouping.keys()): \n",
    "        #if they are both there do it (dipy method may preclude this)\n",
    "        if np.logical_and((currentRenumberIndex1,currentRenumberIndex2) in grouping.keys(),(currentRenumberIndex1,currentRenumberIndex2) in grouping.keys()): \n",
    "            currentIndexes=np.concatenate((np.asarray(grouping[currentRenumberIndex1,currentRenumberIndex2]),np.asarray(grouping[currentRenumberIndex2,currentRenumberIndex1]))).astype(int)\n",
    "        elif (currentRenumberIndex1,currentRenumberIndex2) in grouping.keys():\n",
    "            currentIndexes=grouping[currentRenumberIndex1,currentRenumberIndex2]\n",
    "        elif (currentRenumberIndex2,currentRenumberIndex1) in grouping.keys():\n",
    "            currentIndexes=grouping[currentRenumberIndex2,currentRenumberIndex1]\n",
    "        #there are no other potential cases\n",
    "        subTractogram=extractSubTractogram(sourceTractogram,currentIndexes)\n",
    "        %matplotlib inline\n",
    "        plotParcellationConnectionWidget(subTractogram.streamlines)\n",
    "    else:\n",
    "        print('connection not present')\n",
    "\n",
    "dropDownList=list(zip(grossAnatList, range(len(grossAnatList))))\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import Dropdown\n",
    "\n",
    "#establish interactivity\n",
    "interact(updateFunction, \n",
    "         regionIndex1=Dropdown(options=dropDownList, value=9, description=\"region1\"), \n",
    "         regionIndex2=Dropdown(options=dropDownList, value=12, description=\"region2\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish more specific endpoint criteria (loosely)\n",
    "In order to prevent certian spurrious streamlines (potentially implausable, and certianly not part of the uncinate) we can include some additional segmentation logic to exclude these streamlines *while also not being so strict as to make the segmentation brittle or overdetermined*.  Two of these loose endpoint criteria will be necessary for the uncinate.  Given that we require the posterior cluster of streamlines to be located in the anterior temporal region we can implement criteria relative to the  dorso-ventral axis and the rostro-caudal axis. \n",
    " \n",
    "###  Dorso-ventral criteria:\n",
    "In general, the endpoints of the uncinate are fairly low in the brain.\n",
    "Furthermore, we note that the arc of the uncinate occurs relatively close to the amygdala.  Because the streamlines of the uncinate approach from the ventral side of the amygdala (as they then proceed anteriorly to the frontal lobes), and reach their apex at around the top of the amygdala, it is necessarily the case that at least one endpoint of these streamlines (namely the posterior/inferior endpoint) is below the top of the amygdala.  Therefore, it is logically necessary that it is *not* the case that both streamline endpoints are superior to the top of the amygdala (or else it couldn't engage in the arcing behavior).  Lets translate this into segmentation logic.\n",
    "\n",
    "First we will begin by generating a plane from the top of the amygdala.  Then we find all streamlines that have **both** streamline endpointsabove this plane (we'll negate this criteria later, to adhere to our logic). Note, using the plane in this way is different than requiring neither streamline to be above this plane.  **This logical operation still permits maximally one endpoint per streamline to be above this plane** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b8abe38b0d469e856a04b2d9bb0f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329d21adf2224e7b886819bcdbc85424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=30.0007381439209, continuous_update=False, description='threshold', ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Begin by generating a plane from the top of the amygdala\n",
    "amygdalaTopPlane=WMA_pyFuncs.planarROIFromAtlasLabelBorder(atlasImg,18, 'superior')\n",
    "\n",
    "# find all streamlines that have both streamline endpoints above this plane (we'll negate this criteria later, to generate our logic)\n",
    "bothAboveAmygBool=WMA_pyFuncs.applyEndpointCriteria(sourceTractogram.streamlines,amygdalaTopPlane,'superior','both')\n",
    "\n",
    "subTractogram=extractSubTractogram(sourceTractogram,np.where(np.logical_not(bothAboveAmygBool)))\n",
    "\n",
    "plotParcellationConnectionWidget(subTractogram.streamlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rostro-caudal criteria\n",
    "\n",
    "In general, the endpoints of the uncinate are fairly *anterior* in the brain as we noted above, the arc of the uncinate occurs relatively close to the amygdala. This is true of the rostro-caudal axis as well. The streamlines of the uncinate have all begun to arc forward anterior of the posterior of the border of the amygdala.  A consequence, similar to the one noted (in bold) in the dorso-ventral criteria discussion, is that it is *not* the case that both endpoints are posterior of this posterior amygdala border.  Lets translate this into segmentation logic.\n",
    "\n",
    "We will begin by generating a plane from the posterior of the amygdala.  Next, we will use this to find all streamlines that have both streamline endpoints posterior to this plane (we'll negate this criteria later, to adhere to our logic). Note, this is different than requiring neither streamline to be anterior to this plane.  **This logical operation still permits maximally one endpoint per streamline to be posterior to\n",
    "this plane**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e801ff8a994254a7a2b85e6976e6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b6ca84829e4533bb70ca7392ee3e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=30.000001907348633, continuous_update=False, description='threshold', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Begin by generating a plane from the top of the amygdala\n",
    "amygdalaPosteriorPlane=WMA_pyFuncs.planarROIFromAtlasLabelBorder(atlasImg,18, 'posterior')\n",
    "\n",
    "# find all streamlines that have both streamline endpoints above this plane (we'll negate this criteria later, to generate our logic)\n",
    "bothPosteriorAmygBool=WMA_pyFuncs.applyEndpointCriteria(sourceTractogram.streamlines,amygdalaPosteriorPlane,'posterior','both')\n",
    "\n",
    "subTractogram=extractSubTractogram(sourceTractogram,np.where(np.logical_not(bothPosteriorAmygBool)))\n",
    "\n",
    "plotParcellationConnectionWidget(subTractogram.streamlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other anatomical criteria\n",
    "\n",
    "### midpoint rostro-caudal criteria:\n",
    "\n",
    "If the arc of the uncinate occurs anterior to the posterior border of the amygdala, it stands to reason that the midpoint of those streamlines would also occur anterior to this border.  Even in the case of more sigmoidally shaped streamlines (as opposed to u or j shaped), which do occur and have their endpoints potentially posterior to the posterior amygdala, the midpoint would still be anterior of this border if the anterior endpoint is to terminate in the anterior frontal lobes.  This can rather straightforwardly be translated into segmentation logic.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we find all streamlines that the midpoint anterior of the same posterior amigdala plane we made earlier.\n",
    "midpointAntOfPosteriorAmygBool=WMA_pyFuncs.applyMidpointCriteria(sourceTractogram.streamlines,amygdalaPosteriorPlane,'anterior');\n",
    "subTractogram=extractSubTractogram(sourceTractogram,np.where(midpointAntOfPosteriorAmygBool))\n",
    "\n",
    "plotParcellationConnectionWidget(subTractogram.streamlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### posterior non-traversal criteria:\n",
    "\n",
    "As it should have been clear by now the category segmentation isinsufficient to isolate the uncinate.  Use bsc_quickPlotClassByName(wbfg,categoryClassification,'left_frontal_to_temporalto confirm this for yourself.  Note that the majority of thenon-uncinate fibers appear to be arcuate fibers.  How can we excludethese fibers?  By applying a plane that selectively targets the arcuate streamlines.\n",
    "\n",
    "Subcortical structures, like the thalamus (and amygdala), tend to be relatively invariant in their location across subjects.  This isfortunate for us, because it looks like all of the arcuate-like fibersextend *past* the posterior of the thalamus.  Lets generate a planar roi that we can use as an exclusion criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorThalPlane=WMA_pyFuncs.planarROIFromAtlasLabelBorder(atlasImg,10, 'posterior')\n",
    "\n",
    "posteriorThalExcludedBool=WMA_pyFuncs.applyNiftiCriteriaToTract(sourceTractogram.streamlines, posteriorThalPlane, True, 'any')\n",
    "\n",
    "subTractogram=extractSubTractogram(sourceTractogram,np.where(np.logical_not(posteriorThalExcludedBool)))\n",
    "\n",
    "plotParcellationConnectionWidget(subTractogram.streamlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine criteria and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c8ca183c9848679c657b4701d4883f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240a85d9540d4d63bb20f12202511076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=30.002716064453125, continuous_update=False, description='threshold', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combinedCriteria=np.all([np.logical_not(bothAboveAmygBool),np.logical_not(bothPosteriorAmygBool),midpointAntOfPosteriorAmygBool,np.logical_not(posteriorThalExcludedBool)],axis=0)\n",
    "print(combinedCriteria)\n",
    "subTractogram=extractSubTractogram(sourceTractogram,np.where(combinedCriteria))\n",
    "\n",
    "plotParcellationConnectionWidget(subTractogram.streamlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
