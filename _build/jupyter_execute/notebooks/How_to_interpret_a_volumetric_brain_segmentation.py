#!/usr/bin/env python
# coding: utf-8

# # How to interpret a volumetric brain segmentation
# 
# In a previous lesson with digital images, we explored the notion of a map/parcellation.  In this chapter we'll do the same for NIfTI data, and see how parcellations are implemented in this context.  Lets begin by loading a parcellation generated by [FreeSurfer](https://surfer.nmr.mgh.harvard.edu/) a software package for neuroimaging data which can, among other things, automatedly segment structural brain data (i.e. a T1) into [known structures and/or areas](https://surfer.nmr.mgh.harvard.edu/fswiki/CorticalParcellation).  Note that this parcellation *is specific to* a particuar subject and data source, in this case, it was derived from the subject and source (T1) that we viewed in the previous lesson.

# In[1]:


#this code ensures that we can navigate the WiMSE repo across multiple systems
import subprocess
import os
#get top directory path of the current git repository, under the presumption that 
#the notebook was launched from within the repo directory
gitRepoPath=subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode('ascii').strip()

#move to the top of the directory
os.chdir(gitRepoPath)

import nibabel as nib
#establish path to parcellation
atlasPath=os.path.join(gitRepoPath,'exampleData','parc.nii.gz')
#load it as an object
atlasImg = nib.load(atlasPath)
#extract the header information
atlasHeader = atlasImg.header
print(atlasHeader)  


# Lets take a quick moment to look at how this compares to our source T1.

# In[2]:


#this code ensures that we can navigate the WiMSE repo across multiple systems
import subprocess
import os
#get top directory path of the current git repository, under the presumption that 
#the notebook was launched from within the repo directory
gitRepoPath=subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode('ascii').strip()

#move to the top of the directory
os.chdir(gitRepoPath)

#set path to T1
t1Path=os.path.join(gitRepoPath,'exampleData','t1.nii.gz')

#load the t1
t1img = nib.load(t1Path)
#extract the header info
T1header = t1img.header
#print the output
print(T1header)


# Lets compare a few of these fields.  Specifically:  
# 
# - Data dimensions (**dim**)
# - Voxel dimensions (**pixdim**)
# - Affine (**qoffset_** & **srow_**)

# In[3]:


#get parcellation data shape and print it
print('Atlas Data Dimensions')
atlasDataDimensions=atlasImg.shape
print(atlasDataDimensions)
#get T1 data shape and print it
print('T1 Data Dimensions')
t1DataDimensions=t1img.shape
print(t1DataDimensions)
print('')

#print parcellation voxel dimensions 
print('Atlas Voxel dimensions (in mm)')
parcellationVoxelDims=atlasImg.header.get_zooms()
print(parcellationVoxelDims)
#print T1 voxel dimensions
T1VoxelDims=t1img.header.get_zooms()
print('T1 Voxel dimensions (in mm)')
print(T1VoxelDims)
print('')

#display volume occupied for Atlas
print('Volume of space represented by parcellation')
print(f'{atlasDataDimensions[0]*parcellationVoxelDims[0]} mm by {atlasDataDimensions[1]*parcellationVoxelDims[1]} mm by {atlasDataDimensions[2]*parcellationVoxelDims[2]} mm' )
#display volume occupided for T1
print('Volume of space represented by T1')
print(f'{t1DataDimensions[0]*T1VoxelDims[0]} mm by {t1DataDimensions[1]*T1VoxelDims[1]} mm by {t1DataDimensions[2]*T1VoxelDims[2]} mm' )


# Above we see that there are obvious discrepancies between the internal structure of these data objects.  Although both are composed of isometric, 1 mm voxels, only the parcellation forms a proper cube (with all sides being of the same length/size).  Furthermore, the parcellation characterizes a larger volume of space.
# 
# We'll come back to this as we try and align these images.  For now, lets move towards a consideration of the actual data content of the parcellation data object. 

# In[4]:


import numpy as np
#open it as a numpy data array
atlasData = atlasImg.get_fdata()
#set the print option so it isn't printing in scientific notation
np.set_printoptions(suppress=True)
#condense to unique values
uniqueAtlasEntries=np.unique(atlasData).astype(int)

#print the output
print('Numbers corresponding to unique labels in this atlas')
print('')
print(uniqueAtlasEntries)


# Just as we did before with our T1 data, lets also consider the frequency of these values as well.

# In[5]:


#transform data array for use
unwrappedAtlasData=np.ndarray.flatten(atlasData)

#this time we'll use pandas to do our count, as this will help with plotting
import pandas as pd
#convert single vector numpy array to dataframe
AtlasLabelsDataframe=pd.DataFrame(unwrappedAtlasData)
#count unique values via pandas function
AtlasLabelCounts=AtlasLabelsDataframe.iloc[:,0].value_counts().reset_index()
#rename the columns
AtlasLabelCounts=AtlasLabelCounts.rename(columns={"index":"Label Number",0:"voxel count"})
#round, for the sake of clarity, and resort them by label number
AtlasLabelCounts=AtlasLabelCounts.astype(np.int64).sort_values(by="Label Number").reset_index(drop=True)
#use itables for interactive tables, 
#NOTE SEEMS TO BE BROKEN, FIX AT LATER DATE
import itables
#itables.show(AtlasLabelCounts,columnDefs=[{"width": "10px", "targets": [0,1]}])
#itables.show(AtlasLabelCounts)
AtlasLabelCounts.head(40)


# It seems that our frequency values are traversing several orders of magnitude.  Just for the sake of easy visualization, lets leave off the top three most common values (0, 41, 2) and plot 3 histogram of the rest, splitting them at values below 10000, between 10000 and 12000, and above 12000.
# 
# Some values we can take note of right off the bat are 0, 2 and 41.  These correspond to the background (i.e. unlabeled entries), left cerebral white matter, and right cerebral white matter.  The extremely large value assoicated with "background" (15382362) [] is indicative of what proportion of the data volume is actually associated with labeled entries. Likewise, the values for left and right cerebral white matter (268665 and 265864) are indicative of the large ammount of brain "real estate" occupied by the undifferentiated white matter labels.  Ultimately, it will be our task as budding white matter segmenters to divide those areas up more sensibly, but for now lets look at a plot of the relative size of the brain volumes occupied by these labels.  We have opted not to plot the data for background, left and right cerebral white matter because of how they would informatively dwarf the other values.  Also, keep in mind, that given the resolution of the atlas we are using (1 mm^3, isotropic) the values you note in the subsequent plot can be interpreted as cubic millimeters _or_ as milileters (so as to compare to intuitive refernce volumes like a standard 12oz soda can, which contains ~ 355 ml of liquid).

# In[6]:


#figure out a way to plot/illustrate this better?
#drop the 0,41,2 values
labelsSubset=AtlasLabelsDataframe.loc[~AtlasLabelsDataframe.loc[:,0].isin([0,41,2])]
#reset the index
labelsSubset=labelsSubset.reset_index(drop=True)
#rename the column
labelsSubset=labelsSubset.rename(columns={0:"Label Number"})
#now split the values

lowerLabels=labelsSubset.loc[labelsSubset.iloc[:,0].le(10000)]
#reset the index
lowerLabels=lowerLabels.reset_index(drop=True)

midLabels=labelsSubset.loc[np.logical_and(~labelsSubset.iloc[:,0].le(10000),~labelsSubset.iloc[:,0].ge(12000))]
#reset the index
midLabels=midLabels.reset_index(drop=True)

upperLabels=labelsSubset.loc[labelsSubset.iloc[:,0].ge(12000)]
#reset the index
upperLabels=upperLabels.reset_index(drop=True)

#import seaborn and matplotlib for plotting
import seaborn as sns
import matplotlib.pyplot as plt
get_ipython().run_line_magic('matplotlib', 'inline')
fig, (ax1,ax2,ax3)=plt.subplots(1, 3)
fig.tight_layout(pad=3.0)
sns.countplot(y='Label Number',data=lowerLabels,ax=ax1)
#plt.gcf().set_size_inches(10,30)
#plt.figure(figsize=(10,30),dpi=200)

sns.countplot(y='Label Number',data=midLabels,ax=ax2)
#plt.gcf().set_size_inches(10,30)
#plt.figure(figsize=(10,30),dpi=200)

sns.countplot(y='Label Number',data=upperLabels,ax=ax3)
plt.gcf().set_size_inches(10,30)
#plt.figure(figsize=(10,30),dpi=200)


# In the above histograms we get a sense of how many voxels (on the *count* axis) of the atlas correspond to each numerical label (on the *Label Number*' axis).  We see that some of these occur many thousands of times, while others occur quite a bit more infrequently.  Furthermore, you might also notice that the bottom two plots are roughly identical, this is because these two sets of numbers (11xyz and 12xyz) correspond to the left and right variants of the same structures in the current brain.  This is a standard feature of this particular freesurfer parcellation.  Lets consider the meaning of these numeric labels a bit more in depth.
# 
# Previously, when we were looking at the "paint-by-numbers" map of the united states, we noted that a parcellation is only really useful if we know the categories/framework the parcellations are mapping.  As it turns out the parcellation we are looking at here is very well documented, and the meaning of these labels is quite clear. Freesurfer's documentation includes a [listing of all possible label values](https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT).  Lets load this list up here and consider the names of the regions that we have labeled here.

# In[7]:


#this code ensures that we can navigate the WiMSE repo across multiple systems
import subprocess
import os
#get top directory path of the current git repository, under the presumption that 
#the notebook was launched from within the repo directory
gitRepoPath=subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode('ascii').strip()

#move to the top of the directory
os.chdir(gitRepoPath)

#establish path to table
FSTablePath=os.path.join(gitRepoPath,'exampleData','FreesurferLookup.csv')

#read table using pandas
FSTable=pd.read_csv(FSTablePath)
#print the table interactively
#itables.show(FSTable,columnDefs=[{"width": "10px", "targets": [0,2, 3, 4,5]}])
FSTable.tail(30)


# Here we see the list of possible label numbers (under **#No**), the the names of the anatomical regions they correspond to (under **LabelName**), and the internal color table assigned by Freesurfer (for plotting applications in FreeSurfer) under **R,G, & B**.  Although there are over 1,000 entries here, any given parcellation will only have have a subset of these.  This is because [this table](https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT)(taken from the freesurfer website) actually covers several, mutually exclusive, parcellation schemas.  In this way, two labels/numbers may correspond to overlapping areas of cortex (and thus the same constituent voxels of the associated T1 image).  For example, this would be the case with the label for the superior frontal gyrus from the Desikan-Killiany atlas[citation]--1028-- the superior frontal gyrus from the ["Destrieux" 2009 atlas](https://dx.doi.org/10.1016%2Fj.neuroimage.2010.06.010)--11116.  Note though, that in any given parcellation data object, any particular voxel could only be associated with *one* of these numbers/labels, and this would be determined by the parcellation schema (i.e. "ontology") that the parcellation data object was derived from. 
# 
# Lets limit our view of the table to consider only those labels that are present in our current nifti object *and* augment the table column or how many pixels correspond to that entry.

# In[8]:


#create a boolean vector for the indexes which are in uniqueAtlasEntries
currentIndexesBool=FSTable['#No.'].isin(uniqueAtlasEntries)

#create new data frame with the relevant entries
currentParcellationEntries=FSTable.loc[currentIndexesBool]
#reset the indexes, whicj were disrupted by the previous operation
currentParcellationEntries=currentParcellationEntries.reset_index(drop=True)
#join the FS table subset with the voxel count
#note that we can drop the "Label Number" column of AtlasLabelCounts
#because the indexes of both dataframes track the label number
currentParcellationEntries=currentParcellationEntries.join(AtlasLabelCounts["voxel count"],how="left")

#display the table interactively
#itables.show(currentParcellationEntries,columnDefs=[{"width": "10px", "targets": [2, 3, 4,5]}]) 
currentParcellationEntries.tail(30)


# There are several features to note about this specific parcellation schema, the ["Destrieux" 2009 atlas](https://dx.doi.org/10.1016%2Fj.neuroimage.2010.06.010):
# 
# - The "Unknown" entries are extremly numerous.  These constitute the background voxels--those for which no explicit anatomical mapping exists.  Thus even voxels without a direct mapping still have a numerical label attached to them.
# - Numbers below 1000 (at least of the entries we see) correspond to sub-cortical structures
# - Similarly, numbers above 10000 correspond to cortical structures
# - 5 digit numbers that start with a 11 correspond to left hemisphere, while 5 digit numbers that start with a 12 correspond to the right hemisphere
# 
# These characteristics are not true of all parcellation schemas, but they do make a parcellation easier to work with.  Particularly, numerical regularities that indicate anatomical features (i.e. cortical vs. subcortical, left hemisphere vs right hemisphere, etc.) are of great use.
# 
# Now that we have taken a look our atlas's labels and their voxel counts, lets see how they are spatially laid out in the data volume.

# In[9]:


from niwidgets import NiftiWidget

#in order to have visually distinguishable areas we have to renumber the labels in the data object
#this is because niwidgets scales the color map via the min and max values of the labeling scheme,
#rather than by unique values
relabeledAtlas=atlasData.copy()

#iterate across unique label entries
for iLabels in range(len(uniqueAtlasEntries)):
    #replace the current uniqueAtlasEntries value with the iLabels value
    #constitutes a simple renumbering schema
    relabeledAtlas[relabeledAtlas==uniqueAtlasEntries[iLabels]]=iLabels


#this code ensures that we can navigate the WiMSE repo across multiple systems
import subprocess
import os
#get top directory path of the current git repository, under the presumption that 
#the notebook was launched from within the repo directory
gitRepoPath=subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode('ascii').strip()

#move to the top of the directory
os.chdir(gitRepoPath)

#establish path to new nifti file
newAtlasPath=os.path.join(gitRepoPath,'exampleData','renumberedAtlas.nii.gz')   

#store the modified atlas data in a nifti object
renumberedAtlasNifti=nib.Nifti1Image(relabeledAtlas, atlasImg.affine, atlasImg.header)  
#save the object down
nib.save(renumberedAtlasNifti, newAtlasPath)

#plot it
atlas_widget = NiftiWidget(newAtlasPath)
atlas_widget.nifti_plotter(colormap='nipy_spectral')


# As you use the above sliders to move through the parcellation there are several things to take note of.  First and perhaps most striking,  while the saggital view may be appropriately labled, it is oriented in a somewhat disorienting fashion (typically we might expect this to be oriented such that the left and right axes of the plot correspond to the anterior-posterior axis of the brain).  The coronal and axial slices are switched, but even switching them back wouldn't be a complete solution, as the mislabeled axial slice appears to be upside down.  These observations combined suggest that the affine matrix is either incorrect or is being interpreted incorrectly.  We'll consider this issue a bit more in the next chapter when we briefly look at affines for nifti images.  For now though, we can consider some other features of the visualization.
# 
# Another feature of the visualization we can note is the qualatitive fashion which the parcellation actually "parcellates" (divides into pieces) the brain.  The vibrant, "color-by-numbers" image we're seeing above quite litteraly illustrates the distinct numerical entries in the NIfTI data object.  Just as in the digital image parcellation case, each data structure element can hold a single integer value, and can thus be associated with one, and *only* one, label, and by extension, color.  Multiple integers (and thus assignments) simply *won't* fit in the same data entry in the parcellation data structure.  
# 
# As a general note that is particular to brain parcellations, the anatomical entities represented in a parcellation will vary depending on what method and/or "ontology" (list of anatomical entities which are considered to "exist" for the purposes of a given parcellation) is applied.  For example, the brain regions represented in the parcellation presented above are derived from the ["Destrieux" 2009 atlas](https://dx.doi.org/10.1016%2Fj.neuroimage.2010.06.010).  The parcelled regions in this atlas (and the majority of other brain atlases, for that matter) correspond to brain regions which exhibit structural, functional, and/or microstructural homogenities relative to their neighboring brain regions.
# 
# Now that we have explored three dimensional parcellations a bit, lets move on to a consideration of affine transforms and how they can be used to align parcellations with raw data.

# In[ ]:




