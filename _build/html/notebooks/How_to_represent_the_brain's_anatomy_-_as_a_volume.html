

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>How to represent the brain’s anatomy - as a volume &#8212; White Matter Segmentation Education (WiMSE)</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script type="text/javascript" src="../_static/togglebutton.js"></script>
    <script type="text/javascript" src="../_static/clipboard.min.js"></script>
    <script type="text/javascript" src="../_static/copybutton.js"></script>
    <script type="text/javascript" src="../_static/sphinx-book-theme.js"></script>
    <script type="text/javascript">var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script type="text/javascript" src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" type="text/javascript" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script type="text/javascript">
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" type="text/javascript" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="A quick demonstration of linear affine transformations in 3-D" href="A_quick_demonstration_of_linear_affine_transformations_in_3-D.html" />
    <link rel="prev" title="A consideration of jpegs and brain images" href="A_consideration_of_jpegs_and_brain_images.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">White Matter Segmentation Education (WiMSE)</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../landingPage.html">
   White Matter Segmentation Education (WiMSE)
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Front matter
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Author_and_funding_information.html">
   Author and Funding information
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapterSummaries.html">
   White Matter Segmentation Education - WiMSE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Building intuitions with digital images
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Why_are_we_talking_about_JPEGs.html">
   Why are we talking about JPEGs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Intro_to_discretized_image_representation_&amp;_maps.html">
   Introduction to discritized image representation and maps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Aligning_two_images.html">
   Aligning two images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Multi_object_maps_in_images.html">
   Multi object maps in images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="A_consideration_of_jpegs_and_brain_images.html">
   A consideration of jpegs and brain images
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Working with NIfTI data
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   How to represent the brain’s anatomy - as a volume
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="A_quick_demonstration_of_linear_affine_transformations_in_3-D.html">
   A quick demonstration of linear affine transformations in 3-D
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="How_to_interpret_a_volumetric_brain_segmentation.html">
   How to interpret a volumetric brain segmentation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  White matter and tractography
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Highways_of_the_brain.html">
   Highways of the brain
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="The_measurement,_the_object,_and_the_modality_-_What's_measured_in_diffusion_imaging.html">
   The measurement, the object, and the modality - Whats in measured in diffusion imaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="The_voxel_and_the_streamline.html">
   The voxel and the streamline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="The_source_tractogram.html">
   The source tractogram
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Segmenting tractography
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="A_first_segmentation.html">
   A first segmentation
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/How_to_represent_the_brain's_anatomy_-_as_a_volume.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        
        <a class="edit-button" href="https://github.com/DanNBullock/WiMSE/edit/master/notebooks/How_to_represent_the_brain's_anatomy_-_as_a_volume.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/DanNBullock/WiMSE/master?urlpath=tree/notebooks/How_to_represent_the_brain's_anatomy_-_as_a_volume.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/DanNBullock/WiMSE/blob/master/notebooks/How_to_represent_the_brain's_anatomy_-_as_a_volume.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            
        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="how-to-represent-the-brain-s-anatomy-as-a-volume">
<h1>How to represent the brain’s anatomy - as a volume<a class="headerlink" href="#how-to-represent-the-brain-s-anatomy-as-a-volume" title="Permalink to this headline">¶</a></h1>
<p>Not unlike the way that the satellite images of the the previous chapters were a “picture” of the world, a T1 image can be thought of as a “picture” of a brain in a similar fashion.  The specics of how the dimagnetic properties of water molecules are legeraged, along with the use of a superconducting magnet, to obtain these images are beyond the scope of this lesson book.  For now let us keep the analogy of the jpeg image in mind as we move into a consideration of the nifti itself.</p>
<p>Lets begin by loading it into memory and considering its data size.  Whereas previously we were working with .jpg and .png files, we will now be working with .nifti files, which are typically stored as .nii.gz, which corresponds to a compressed state.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#this code ensures that we can navigate the WiMSE repo across multiple systems</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="c1">#get top directory path of the current git repository, under the presumption that </span>
<span class="c1">#the notebook was launched from within the repo directory</span>
<span class="n">gitRepoPath</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">([</span><span class="s1">&#39;git&#39;</span><span class="p">,</span> <span class="s1">&#39;rev-parse&#39;</span><span class="p">,</span> <span class="s1">&#39;--show-toplevel&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;ascii&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

<span class="c1">#move to the top of the directory</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">gitRepoPath</span><span class="p">)</span>

<span class="c1">#set path to T1</span>
<span class="n">t1Path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gitRepoPath</span><span class="p">,</span><span class="s1">&#39;exampleData&#39;</span><span class="p">,</span><span class="s1">&#39;t1.nii.gz&#39;</span><span class="p">)</span>
<span class="c1">#obtain file information about the t1 file</span>
<span class="n">T1fileinfo</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">stat</span><span class="p">(</span><span class="n">t1Path</span><span class="p">)</span>

<span class="c1">#print out some of the ifo</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;T1 size (in bytes)&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">T1fileinfo</span><span class="o">.</span><span class="n">st_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>T1 size (in bytes)
5688165
</pre></div>
</div>
</div>
</div>
<p>The T1 NIfTI image we just loaded is about 3.6 MB in size, which is roughly close to a high resolution digital image file.  Given what we know about digital image (every pixel has 3 to 4 <em>integer</em> values which correspond to its color characteristics), we can get a rough sense about the number data entries contained within a NIfTI, and–by extension–the general amount of “information” (a complex topic we won’t go into here) that a NIfTI image contains about volume of space it is represents.</p>
<p>Quite helpfully, the NIfTI data type features a “header” which contains a great deal of <a class="reference external" href="https://en.wikipedia.org/wiki/Metadata">metadata</a> about the associated image data.  Think of it as being analagous to the <a class="reference external" href="https://en.wikipedia.org/wiki/Exif">Exif</a> data of a typical digital image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#begin process of loading file as a T1 nifti using nibabel</span>
<span class="kn">import</span> <span class="nn">nibabel</span> <span class="k">as</span> <span class="nn">nib</span>
<span class="c1">#import the data</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">nib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">t1Path</span><span class="p">)</span>

<span class="c1">#extract the header info</span>
<span class="n">T1header</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">header</span>
<span class="c1">#print the output</span>
<span class="nb">print</span><span class="p">(</span><span class="n">T1header</span><span class="p">)</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;nibabel.nifti1.Nifti1Header&#39;&gt; object, endian=&#39;&lt;&#39;
sizeof_hdr      : 348
data_type       : b&#39;&#39;
db_name         : b&#39;&#39;
extents         : 0
session_error   : 0
regular         : b&#39;r&#39;
dim_info        : 0
dim             : [  3 182 218 182   1   1   1   1]
intent_p1       : 0.0
intent_p2       : 0.0
intent_p3       : 0.0
intent_code     : none
datatype        : int16
bitpix          : 16
slice_start     : 0
pixdim          : [-1.   1.   1.   1.   1.8  0.   0.   0. ]
vox_offset      : 0.0
scl_slope       : nan
scl_inter       : nan
slice_end       : 0
slice_code      : unknown
xyzt_units      : 10
cal_max         : 0.0
cal_min         : 0.0
slice_duration  : 0.0
toffset         : 0.0
glmax           : 0
glmin           : 0
descrip         : b&#39;FSL5.0&#39;
aux_file        : b&#39;&#39;
qform_code      : mni
sform_code      : mni
quatern_b       : 0.0
quatern_c       : 1.0
quatern_d       : 0.0
qoffset_x       : 90.0
qoffset_y       : -126.0
qoffset_z       : -72.0
srow_x          : [-1.  0.  0. 90.]
srow_y          : [   0.    1.    0. -126.]
srow_z          : [  0.   0.   1. -72.]
intent_name     : b&#39;&#39;
magic           : b&#39;n+1&#39;
</pre></div>
</div>
</div>
</div>
<p>That’s a lot of information!</p>
<p>For now, we’ll only briefly consider a few of these features, but we’ll to each of these as we necessary as we proceed through the next set of lessons.</p>
<p><a class="reference external" href="https://nifti.nimh.nih.gov/nifti-1/documentation/nifti1fields/nifti1fields_pages/dim.html/document_view"><strong>dim</strong></a>:  This field displays the dimensions of the NIfTI image data object.  The first number (3, in this case) indicates the total number of dimensions occupied by the data.  The next several values (as many as indicated by the first number in this vector) correspond to the span of each of those dimensions.  Thus, in this case the first dimension spans 145 entries, the second spans 174 entires, and the third spans 145 entries.</p>
<p><a class="reference external" href="https://nifti.nimh.nih.gov/nifti-1/documentation/nifti1fields/nifti1fields_pages/datatype.html"><strong>datatype</strong></a>:  This field corresponds to the <a class="reference external" href="https://en.wikipedia.org/wiki/Computer_number_format"><em>type</em> of numerical data</a>  contained within each of the nifti image data object’s entries.  Here we see that it is “float32”.  This gives us two primary peices of information: (1) we now know that the numerical entries are <em>not</em> integers or whole numbers (and thus they can adopt values <em>between</em> 1,2,3, etc.)  and (2) we now know that each of these entries <a class="reference external" href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format">takes up about 4 bytes</a>.</p>
<p><a class="reference external" href="https://nifti.nimh.nih.gov/nifti-1/documentation/nifti1fields/nifti1fields_pages/pixdim.html/document_view"><strong>pixdim</strong></a>:  Ignoring the initial (-1) and last four values in this field (1.8 0. 0. 0.), we see the numbers 1. 1. 1..   These indicate the size of the dimensions of real world space reprsented by the NIfTI image data object’s entries.  In the case of the map from the previous chapter, this would have corresponded roughly to hundreds of square miles (though the exact quantity would be complex issue given that the pixels dont correspond the same surface area size).  In this case, we see that each of these values is 1 millimeter, which means that the data in any entry of the NIfTI represents a 1 by 1 by 1 for a total of 1 cubic millimeter volume of space.  The fifth value (1) isn’t particularly relevant to this particular nifti, as our nifti data object is only 3 dimensional.  If we were examining fMRI data, this value would indicate the timestep used for the data.</p>
<p>Also, its important to note that all three of the spatial dimension measures examined above are the same.  This need not be the case, and it could be that our voxels are actually representing units of space whose sides are not all equal.  In this case though, we can say that the voxels are “isometric”, meaning that all faces are the same size.</p>
<p><a class="reference external" href="https://nifti.nimh.nih.gov/nifti-1/documentation/nifti1fields/nifti1fields_pages/qsform.html"><strong>qform_code</strong></a>:  This field specifies the orientation schema that will be detailed in subsequent fields.  In the previous lesson we considered the intersection of the <a class="reference external" href="https://en.wikipedia.org/wiki/IERS_Reference_Meridian">prime maridian</a> and <a class="reference external" href="https://en.wikipedia.org/wiki/Equator">equator</a> as the “origin” of the major orientation schema we used, and endeavored to overlay these locations when we aligned global satellite images.  But imagine that we instead used some other coordinate system to establish a different origin point.  Alternatively, what if we stopped using degrees as our unit of measure or that we flipped our labeling convention for east and west? In any of these cases, we would need to find a way to indicate what our refrence frame was.  This need for specification of orientation system is reflected in the <strong>qform_code</strong> of the NIfTI header.  Here, we have some indicator (“mni” or “talarach”, for example) that establish a common refrence frame for orienting the image data.  “mni” and “talarach” respectively correspond to the standard Montreal Neurological Institute [citation] and Talairach [citation] atlases.  These and other neuroimaging reference frames are well described <a class="reference external" href="http://www.fieldtriptoolbox.org/faq/how_are_the_different_head_and_mri_coordinate_systems_defined/">elsewhere</a>.</p>
<p><a class="reference external" href="https://nifti.nimh.nih.gov/nifti-1/documentation/nifti1fields/nifti1fields_pages/qsform.html"><strong>qoffset_x, qoffset_y , qoffset_z</strong></a> (see “METHOD 2”):  These numbers are the transforms necessary to align this image to the reference specified in “qform_code”.  Referring back to our previous lessons, you can think of these numbers as the shift needed to align the political map with the geographic map. Now though, we have three dimensions (as opposed to two) and need to align each of them.  Typically our goals when aligning MRI images  are threefold:  (1) that the images share matching scales, (2) that the images exhibit the same orientation (e.g. top -&gt; top, left -&gt; left, etc.), and (3) that the images points share the same “origin”.</p>
<p>We have now looked at some important features of the <a class="reference external" href="https://nifti.nimh.nih.gov/pub/dist/src/niftilib/nifti1.h">NIfTI header</a>.  However, we haven’t yet taken a look the actual data component of a NIfTI, as we did with digital images in previous lessons.  Lets move forward at take a look at this now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Data dimensions&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;(How many data entries are spanned across each dimension)&#39;</span><span class="p">)</span>
<span class="c1">#extract data dimensions and store in DataDimensions variable</span>
<span class="n">dataDimensions</span><span class="o">=</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataDimensions</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data dimensions
(How many data entries are spanned across each dimension)
(182, 218, 182)
</pre></div>
</div>
</div>
</div>
<p>Here we are no longer indexing into the header, but we nontheless see that the size of the image data is (182,218,182), which is consistent with the information we obtained from the “dim” field of the header.  In theory, the metadata contained should always be consistent with the actual data, but it is possible for these to become inconsistent due to improper file generation or manipulation.</p>
<p>It’s also worth noting that the <a class="reference external" href="https://nipy.org/nibabel/">nibabel</a> offers a number of methods for extracting <em>specific</em> information from the header.  For example, we can extract the information specific to the spatial dimensions of the image we are looking at.  This capability can be helpful when performing series of computations or developing your own sets of functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Voxel dimensions for T1 (in mm)&#39;</span><span class="p">)</span>
<span class="c1">#extract dimensions and store in voxelDims variable</span>
<span class="n">voxelDims</span><span class="o">=</span><span class="n">img</span><span class="o">.</span><span class="n">header</span><span class="o">.</span><span class="n">get_zooms</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">voxelDims</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Voxel dimensions for T1 (in mm)
(1.0, 1.0, 1.0)
</pre></div>
</div>
</div>
</div>
<p>Here, we obtain a result that matches what we saw by looking at the entire header.  Now though we have stored this specific information in a variable.  Now, by taking the size of an individual voxel and the dimensions of the entire data block we can compute the amount of space that this nifti represents.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;How much total space does this representation correspond to?&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;{dataDimensions[0]*voxelDims[0]} mm by {dataDimensions[1]*voxelDims[1]} mm by {dataDimensions[2]*voxelDims[2]} mm&#39;</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>How much total space does this representation correspond to?

182.0 mm by 218.0 mm by 182.0 mm
</pre></div>
</div>
</div>
</div>
<p>For those more comfortable with imperial measurements, this corresponds to a volume of space that is slightly more than half a foot wide (~.6 feet), almost three quarters of a foot tall (~.71 feet), and slightly more than half a foot deep (~.6 feet).  This information gives us a sense of the gross scale of the data contained within a NIfTI.  But what about the data contained within a specific entry?  Whats in a voxel?</p>
<p>Lets actually index into a specific voxel and see what information is stored there.  From the header, we know that it will be a float value, but we dont, as of yet, have a ballpark sense of what this value will be.  We’ll just arbitrarily pick a value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#extract the actual data into the variable data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">get_fdata</span><span class="p">()</span>
<span class="c1">#arbitrarily index into the item the 96 X, 86 Y, 57 Z location and read it out</span>
<span class="n">data</span><span class="p">[</span><span class="mi">96</span><span class="p">,</span><span class="mi">86</span><span class="p">,</span><span class="mi">57</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>235.0
</pre></div>
</div>
</div>
</div>
<p>235.0.  We don’t really know what this number means, whether it is a lot or a little, or if it is un usual, but it at least gives us some sense of the kind of numbers this NIfTI object contains.  What about all of the others though?  How can we get a comprehensive and informative sense of those?  Lets take a hint from our digital image lessons and explore this NIfTI data by plotting a histogram of the data values for each voxel.  In a certian sense, we’re lucky (relative to the digital image case) because we can plot a sensible histogram for this information, as there aren’t 3 distinct color channels to worry about (which would make it difficult to interpret a histogram or set of histograms).  Additionally, we can get a sense of what how many total voxels there are, how many are “non-zero” (in that they contain a measure distinct from zero), and what proportion of the total number of voxels this corresponds to. Lets do that now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="c1">#necessary for plotting</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="c1">#transform data array for use</span>
<span class="n">unwrappedData</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total number of voxels&#39;</span><span class="p">)</span>
<span class="c1">#compute total number of voxels via straightforward multiplication</span>
<span class="n">voxTotal</span><span class="o">=</span><span class="n">dataDimensions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">dataDimensions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">dataDimensions</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">voxTotal</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Minimum voxel value&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">unwrappedData</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Maximum voxel value&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">unwrappedData</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="c1">#set value at which to split the data</span>
<span class="c1">#Operating under the assumption that negative values are not viable</span>
<span class="n">splitPoint</span><span class="o">=</span><span class="mi">0</span>

<span class="c1">#define two functions for obtaining boolean vectors for numerical comparison</span>
<span class="k">def</span> <span class="nf">smallVal</span><span class="p">(</span><span class="n">n</span><span class="p">):</span> 
    <span class="k">return</span> <span class="n">n</span><span class="o">&lt;=</span><span class="n">splitPoint</span>
<span class="k">def</span> <span class="nf">largeVal</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">n</span><span class="o">&gt;</span><span class="n">splitPoint</span>

<span class="c1">#apply the function to the unwrapped data</span>
<span class="n">result</span><span class="o">=</span><span class="nb">map</span><span class="p">(</span><span class="n">smallVal</span><span class="p">,</span><span class="n">unwrappedData</span><span class="p">)</span>
<span class="c1">#convert the output to a usable format </span>
<span class="n">smallBool</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="c1">#apply the function to the unwrapped data</span>
<span class="n">result</span><span class="o">=</span><span class="nb">map</span><span class="p">(</span><span class="n">largeVal</span><span class="p">,</span><span class="n">unwrappedData</span><span class="p">)</span>
<span class="c1">#convert the output to a usable format </span>
<span class="n">largeBool</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of voxel values less than or equal to zero&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">smallBool</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of voxel values greater than zero&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">largeBool</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Proportion of entries greater than zero (i.e. containing data)&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">largeBool</span><span class="p">)</span><span class="o">/</span><span class="n">voxTotal</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="c1">#perform plotting of zero/negative values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">unwrappedData</span><span class="p">[</span><span class="n">smallBool</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Voxel Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Number of Voxels&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distributon of voxel less than or equal to zero&#39;</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mf">18.5</span><span class="p">,</span> <span class="mf">10.5</span><span class="p">)</span>

<span class="c1">#perform plotting of positive values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">unwrappedData</span><span class="p">[</span><span class="n">largeBool</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Voxel Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Number of Voxels&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distributon of voxel values greater than zero&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total number of voxels
7221032

Minimum voxel value
-37.0

Maximum voxel value
789.0

Number of voxel values less than or equal to zero
2203910

Number of voxel values greater than zero
5017122

Proportion of entries greater than zero (i.e. containing data)
0.6947929326445306
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Distributon of voxel values greater than zero&#39;)
</pre></div>
</div>
<img alt="../_images/How_to_represent_the_brain's_anatomy_-_as_a_volume_13_2.png" src="../_images/How_to_represent_the_brain's_anatomy_-_as_a_volume_13_2.png" />
</div>
</div>
<p>It seems that about a quarter of the voxels contain data that we would consider to be reprsentatve of the brain, with the assumption that “empty” voxels correspond to background and/or uninformative voxels.  Depending on whether or not this T1 has had the brain “extracted” (i.e. the brain isolated from the rest of the head, neck, and body, via a masking process), this proporation may also include non-brain tissues.  Indeed, given that we took a look at this very same T1 image in the previous lesson, we know that this is the case an that the brian has been isolated from non brain tissues.  Furthermore, note how we had to split the histogram in two.  Had we not done this, the number of empty voxels would have overwhelmed the visualization and we wouldn’t have been able to observe the distribution visible in the plot on the right due to the extreme number of values right below 0.</p>
<p>Now that we have a sense of the numerical variability of the data in this nifti, lets get a sense of how these values are laid out spatially.  Keep in mind that, just like a digital image wherein the i,j entry of the data array represents a portion of space that spatially adjacent to the i,j-1 (or i,j+1, or i+1,j etc.), the i,j,k entry of a NIfTI is spatially adjacent to the i,j,k+1 entry.  We can get a better sense of this by interacting with the NIfTI using a <a class="reference external" href="https://nipy.org/niwidgets/">niwidget</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">niwidgets</span> <span class="k">import</span> <span class="n">NiftiWidget</span>

<span class="n">t1Widget</span> <span class="o">=</span> <span class="n">NiftiWidget</span><span class="p">(</span><span class="n">t1Path</span><span class="p">)</span>

<span class="n">t1Widget</span><span class="o">.</span><span class="n">nifti_plotter</span><span class="p">(</span><span class="n">colormap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "07c6ca32872a4d9cb6b42584e08698ee", "version_major": 2, "version_minor": 0}
</script></div>
</div>
<p>Take a moment to shift through the NIfTI image plotted above.  If you want a more standard visualization, feel free to switch the colormap to gray.  <strong>As a challenge, try and shift the x, y, and z sliders to cross at the posterior commisure, and take note of the coordinates of this point</strong>.  Take note that the left, posterior, inferior corner is the 0 coordinate.  The coordinate shift that results in the posterior commisure being at (0,0,0) occurs after the previously qoffset information has been applied.  After this transform has been applied, locations in the left hemisphere are characterized by coorinates that have a negative first value (x coordinate).</p>
<p>As an alternative to trying to find the posterior commisure manually, we can also use the information in the header (assuming its accurate) to compute its location in this image data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;T1 voxel resolution (in mm)&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">header</span><span class="o">.</span><span class="n">get_zooms</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;T1 voxel affine&#39;</span><span class="p">)</span>
<span class="n">imgAff</span><span class="o">=</span><span class="n">img</span><span class="o">.</span><span class="n">affine</span>
<span class="nb">print</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">affine</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Coordinates of posterior commisure&#39;</span><span class="p">)</span>
<span class="c1">#force absolute value in order to perform the math correctly</span>
<span class="n">imgSpatialTrans</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">([</span><span class="n">imgAff</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span><span class="o">/</span><span class="n">imgAff</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">imgAff</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span><span class="o">/</span><span class="n">imgAff</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">imgAff</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span><span class="o">/</span><span class="n">imgAff</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">imgSpatialTrans</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>T1 voxel resolution (in mm)
(1.0, 1.0, 1.0)

T1 voxel affine
[[  -1.    0.    0.   90.]
 [   0.    1.    0. -126.]
 [   0.    0.    1.  -72.]
 [   0.    0.    0.    1.]]

Coordinates of posterior commisure
[ 90. 126.  72.]
</pre></div>
</div>
</div>
</div>
<p>If you move the slider coordinates to the value specified under “Coordinates of posterior commisure”, your crosshair should directly target the posterior commisure.  However, there sign of the numbers in this affine matrix suggest that something may be afoot.  Lets consider in a bit more detail what these numbers might be indicating.</p>
<p>Admittedly, the notion of a shift or transform gets a bit more complicated in three dimensions, where it is possible to have your data rotated or flipped along multiple dimensions.  With a standard 2d image this would have been quite obvious upon inspection–you would notice if the world had been rotated 90% or flipped such that Russia was west of the US’s “east” coast!  Although some of these changes are obvious in a NIfTI image (for example a 90 degree rotation), some are less obvious.  For example, as it turns out, <strong>this brain data is flipped in its x axis!</strong>. Because of this the right hemisphere data is stored in indexes smaller than the X coordinate of the posterior commissure (90) while the left hemisphere data is stored in indexes that are larger than the X coordinate of the posterior commissure.  This is contrary to standard orientation schemas.  Lets take a look at how we could come to know this by taking a look at the [affine transform matrix].(https://en.wikipedia.org/wiki/Affine_transformation) again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;T1 voxel affine&#39;</span><span class="p">)</span>
<span class="n">imgAff</span><span class="o">=</span><span class="n">img</span><span class="o">.</span><span class="n">affine</span>
<span class="nb">print</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">affine</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>T1 voxel affine
[[  -1.    0.    0.   90.]
 [   0.    1.    0. -126.]
 [   0.    0.    1.  -72.]
 [   0.    0.    0.    1.]]
</pre></div>
</div>
</div>
</div>
<p>You’ll notice that the upper left hand value (-1.), which specifies the voxel resolution of the Y dimension, is negative.  This is as opposed to the values found for the Y and Z dimension resolutions, which are postitive.  Considered in conjunction with the information in the first three rows for the rightmost column (the <strong>qoffset_</strong> information from the header), this indicates that a flip in the X dimension is present.  This is why the <em>np.abs</em> function was used earlier when computing the posterior commisure location (NOTE: this strategy will not work for all affine flip cases, but did work in this case).  For more detailed examinations and considerations of affine transforms for neuroimaging data [links]</p>
<p>Now that we have developed a good sense of the information stored in a T1 NIfTI image, lets follow in the footsteps of our lessons looking at two dimensional digital images, and see how a <strong>parcellation</strong> can be implemented using three dimensional NIfTI data.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="A_consideration_of_jpegs_and_brain_images.html" title="previous page">A consideration of jpegs and brain images</a>
    <a class='right-next' id="next-link" href="A_quick_demonstration_of_linear_affine_transformations_in_3-D.html" title="next page">A quick demonstration of linear affine transformations in 3-D</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Daniel Bullock<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>