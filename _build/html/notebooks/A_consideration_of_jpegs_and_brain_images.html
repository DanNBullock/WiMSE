

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>A consideration of jpegs and brain images &#8212; White Matter Segmentation Education (WiMSE)</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script type="text/javascript" src="../_static/togglebutton.js"></script>
    <script type="text/javascript" src="../_static/clipboard.min.js"></script>
    <script type="text/javascript" src="../_static/copybutton.js"></script>
    <script type="text/javascript" src="../_static/sphinx-book-theme.js"></script>
    <script type="text/javascript">var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script type="text/javascript" src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" type="text/javascript" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script type="text/javascript">
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" type="text/javascript" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="How to represent the brain’s anatomy - as a volume" href="How_to_represent_the_brain&#39;s_anatomy_-_as_a_volume.html" />
    <link rel="prev" title="Multi object maps in images" href="Multi_object_maps_in_images.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">White Matter Segmentation Education (WiMSE)</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../landingPage.html">
   White Matter Segmentation Education (WiMSE)
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Front matter
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Author_and_funding_information.html">
   Author and Funding information
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapterSummaries.html">
   White Matter Segmentation Education - WiMSE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Building intuitions with digital images
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Why_are_we_talking_about_JPEGs.html">
   Why are we talking about JPEGs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Intro_to_discretized_image_representation_&amp;_maps.html">
   Introduction to discritized image representation and maps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Aligning_two_images.html">
   Aligning two images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Multi_object_maps_in_images.html">
   Multi object maps in images
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   A consideration of jpegs and brain images
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Working with NIfTI data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="How_to_represent_the_brain's_anatomy_-_as_a_volume.html">
   How to represent the brain’s anatomy - as a volume
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="A_quick_demonstration_of_linear_affine_transformations_in_3-D.html">
   A quick demonstration of linear affine transformations in 3-D
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="How_to_interpret_a_volumetric_brain_segmentation.html">
   How to interpret a volumetric brain segmentation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  White matter and tractography
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Highways_of_the_brain.html">
   Highways of the brain
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="The_measurement,_the_object,_and_the_modality_-_What's_measured_in_diffusion_imaging.html">
   The measurement, the object, and the modality - Whats in measured in diffusion imaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="The_voxel_and_the_streamline.html">
   The voxel and the streamline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="The_source_tractogram.html">
   The source tractogram
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Segmenting tractography
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="A_first_segmentation.html">
   A first segmentation
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/A_consideration_of_jpegs_and_brain_images.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        
        <a class="edit-button" href="https://github.com/DanNBullock/WiMSE/edit/master/notebooks/A_consideration_of_jpegs_and_brain_images.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/DanNBullock/WiMSE/master?urlpath=tree/notebooks/A_consideration_of_jpegs_and_brain_images.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/DanNBullock/WiMSE/blob/master/notebooks/A_consideration_of_jpegs_and_brain_images.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            
        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="a-consideration-of-jpegs-and-brain-images">
<h1>A consideration of jpegs and brain images<a class="headerlink" href="#a-consideration-of-jpegs-and-brain-images" title="Permalink to this headline">¶</a></h1>
<p>Now we move to the first major topical transition in our lesson set.  Up until now we have been working with JPEGs, but now we will move towards working with NIfTI files.  In our exploration of JPEGs we covered the following topics:</p>
<ul class="simple">
<li><p>How an image data object stores information</p></li>
<li><p>How to make a mask by applying a threshold to image data</p></li>
<li><p>How to align two images</p></li>
<li><p>How to utilize an image parcellation</p></li>
</ul>
<p>Note that, despite the JPEG image data being stored across three color channels, all of the major tasks were performed using two dimensional data structures.  The data storage component of <a class="reference external" href="https://nifti.nimh.nih.gov/">NiFTI</a> images is minimally <strong>3</strong> dimensional.  Furthermore, the data the data contained with a NIfTI represents something quite different than what is represented in JPEG image data (think back to the table comparing data formats).</p>
<p>Lets consider these features in a bit more detail.  We’ll considering an example of each JPEG and a NIfTI</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#lets begin by setting up paths and files</span>

<span class="c1">#this code ensures that we can navigate the WiMSE repo across multiple systems</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">matplotlib.pyplot</span> <span class="k">import</span> <span class="n">imshow</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1">#get top directory path of the current git repository, under the presumption that </span>
<span class="c1">#the notebook was launched from within the repo directory</span>
<span class="n">gitRepoPath</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">([</span><span class="s1">&#39;git&#39;</span><span class="p">,</span> <span class="s1">&#39;rev-parse&#39;</span><span class="p">,</span> <span class="s1">&#39;--show-toplevel&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;ascii&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

<span class="c1">#move to the top of the directory</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">gitRepoPath</span><span class="p">)</span>

<span class="c1">#file name of standard map of the world</span>
<span class="n">satelliteName</span><span class="o">=</span><span class="s1">&#39;Earthmap1000x500.jpg&#39;</span>

<span class="c1">#file name of mri images</span>
<span class="n">mriName</span><span class="o">=</span><span class="s1">&#39;T1t2PD.jpg&#39;</span>

<span class="kn">import</span> <span class="nn">PIL</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="k">import</span> <span class="n">Image</span>

<span class="c1">#get satellite image</span>
<span class="n">satelliteMapPath</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gitRepoPath</span><span class="p">,</span><span class="s1">&#39;images&#39;</span><span class="p">,</span><span class="n">satelliteName</span><span class="p">)</span> 
<span class="n">satelliteMap</span><span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">satelliteMapPath</span><span class="p">)</span>
<span class="c1">#in order to display in jupyter, some trickery is necessary</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1">#%matplotlib inline</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">satelliteMap</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/A_consideration_of_jpegs_and_brain_images_1_0.png" src="../_images/A_consideration_of_jpegs_and_brain_images_1_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">niwidgets</span> <span class="k">import</span> <span class="n">NiftiWidget</span>
<span class="kn">from</span> <span class="nn">niwidgets</span> <span class="k">import</span> <span class="n">examplet1</span>

<span class="c1">#pointing to a different nitfti, that doesn&#39;t have huge spaces between values, so that the colormap is discernable</span>
<span class="n">t1Path</span><span class="o">=</span><span class="s1">&#39;/Users/plab/Documents/JupyerData/proj-5c50b6f12daf2e0032f880eb/sub-100206/dt-neuro-anat-t1w.tag-acpc_aligned.tag-brain_extracted.id-5c57072befbc2800526291bb/t1.nii.gz&#39;</span>

<span class="n">t1_widget</span> <span class="o">=</span> <span class="n">NiftiWidget</span><span class="p">(</span><span class="n">t1Path</span><span class="p">)</span>
<span class="n">t1_widget</span><span class="o">.</span><span class="n">nifti_plotter</span><span class="p">(</span><span class="n">colormap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "0549770841c54ffcb83d2c129a4b6457", "version_major": 2, "version_minor": 0}
</script></div>
</div>
<p>Lets begin our comparison by considering the dimensional differences between the data types.</p>
<p>In the previous lessons we noted that our digital image data was stored in 3 layers corresponding to the RGB values mapped to each image pixel.  Thus, although the picture we viewed was two dimensional, the storage object was 3 dimensional (albiet somewhat shallow, at only three “layers” deep).  The image data component of a NIfTI is (typically, for static and/or structural images) a 3 dimensional structure, but this is not because it is storing color data.  Rather, the image data component of a NIfTI object is (typically) three dimensional because the representation the data is trying to capture is <em>actually</em> three dimensional in nature.  The individual image data components, which represent volumes of space and thus constitute <strong>voxels</strong> (rather than pixels), preserve the spatial relations of the volumes they represent, and so adjacent data entries represent adjacent volumes of space across all three dimensions.  This in the same way that adjacent pixels in two dimensional digital images represent adjacent regions of a scene.  The data contained in each of these voxel elements represents a characteristic of the volume it correspons to, but the specific characteristic depends on the MRI scan that generated it, or (in cases of derived or synthetic data) the schema that was use to create the NIfTI data.</p>
<p>As an exercise, we could imagine what it would be like if the NIfTI were to attempt to store something like color data in its object:  our resulting data object would be X by Y by Z by 3 (RGB) color channels in size.  Thus, if a NIfTI were to be storing color information it would  minimally have to be <strong>four</strong> dimensional. However, NIfTIs <strong>are not</strong> storing anything like color information, and so they are typically three dimensional, as in the case of a T1 image, or 4 dimensional, as in the case of fMRI (functional magnetic resonance imaging) and DWI (diffusion weighted imaging) data (we’ll touch on those data modalities briefly in our discussions of neuroimaging data).</p>
<p>Staying on the subject of color for a moment though, we can note that the JPEG image is in color while the NIfTI-derived images are grayscaled. This is a consequence of the data being represented by the image. In the case of a JPEG photo, a camera (of some sort) is used to measure light as it hits a sensor array. The individual sensors are specific (either inherently, or via design features) to specific ranges of wavelenghts of light in the visible range (~380-740 nanometers).  Because of this, the sensors able to collect data about the presented scene in such a way that the same locations are represented multiple times (once for each color channel).  Computer and television screens are then able to recapitulate the scene by passing this stored information to their constituent pixels. Under an 8-bit data storage schema for color information, each pixel in each channel can adopt a value between 0 and 255 meaning that basic forms of RGB can display 255^3=16,581,375 distinct colors. Whether or not the human eye can discern this many colors (and the manner in which the color spectrum is <em>actually</em> mapped by various <a class="reference external" href="https://en.wikipedia.org/wiki/ICC_profile">color schemes</a> is another matter entirely. Regardless, this is the general framework by which a digital image stores reflectance image about a scene.</p>
<p>The manner in which MRI data is depicted by a NIfTI is somewhat different. Like a digital photo–to some extent–the data in a MRI-derived NIfTI contains is the result of measuring photons.  However the process by which the data from MRI devices is converted into a parsable, three dimensional image is incredibly complex and involves mathematical transformation via <a class="reference external" href="https://en.wikipedia.org/wiki/K-space_(magnetic_resonance_imaging)"><em>k-space</em></a>.  Indeed, the specifics of this process are beyond the scope of this lesson set, and are described in great detail elsewhere (CITATION).  What <em>is</em> worth noting though is that each each voxel of the NIfTI structure represents a single volume of space and is stored as a <a class="reference external" href="https://en.wikipedia.org/wiki/Computer_number_format#Floating-point_numbers">floating-point number</a> as opposed to an integer.  This is because the information that the data entries can (and often do) represent can take on non-integer values.</p>
<p>Now that we have talked at some length about the NIfTI data structure, lets take a closer look at an example of one.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="Multi_object_maps_in_images.html" title="previous page">Multi object maps in images</a>
    <a class='right-next' id="next-link" href="How_to_represent_the_brain&#39;s_anatomy_-_as_a_volume.html" title="next page">How to represent the brain’s anatomy - as a volume</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Daniel Bullock<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>