{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Segmentation: uncinate fasiculus\n",
    "\n",
    "[introduction]\n",
    "\n",
    "largely taken from a [recent version of a matlab-based WMA segmentation](https://github.com/DanNBullock/wma_tools/blob/53a4d99b68b832257c55d5f1320dc7266cc8c270/Segmentations/bsc_segmentAntPostTracts_v4.m#L76)\n",
    "\n",
    "\n",
    "## Establishing the category\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debatable:\n",
    "#Planum temporale\n",
    "#fusiform gyrus\n",
    "#oc-temp_med_and_Lingual\n",
    "\n",
    "#this code ensures that we can navigate the WiMSE repo across multiple systems\n",
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "#get top directory path of the current git repository, under the presumption that \n",
    "#the notebook was launched from within the repo directory\n",
    "gitRepoPath=subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode('ascii').strip()\n",
    "\n",
    "#move to the top of the directory\n",
    "os.chdir(gitRepoPath)\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "grossAnatomyPath=os.path.join(gitRepoPath,'exampleData','GrossAnatomyLookup.csv')\n",
    "\n",
    "grossAnatTable=pd.read_csv(grossAnatomyPath)\n",
    "#load the atlas\n",
    "atlasPath=os.path.join(gitRepoPath,'exampleData','parc.nii.gz')\n",
    "#load it as an object\n",
    "atlasImg = nib.load(atlasPath)\n",
    "\n",
    "#get and copy the data\n",
    "relabeledAtlas=atlasImg.get_fdata().copy()\n",
    "\n",
    "#get the labels to iterate over\n",
    "uniqueAtlasEntries=np.unique(atlasImg.get_fdata()).astype(int)\n",
    "\n",
    "grossAnatList=grossAnatTable['GrossAnat'].unique()\n",
    "\n",
    "#iterate across unique label entries\n",
    "for iLabels in range(len(uniqueAtlasEntries)):\n",
    "    #print(np.isin(grossAnatTable['GrossAnat'].loc[grossAnatTable['#No.']==uniqueAtlasEntries[iLabels]],grossAnatList))\n",
    "    #replace the current uniqueAtlasEntries value with the label corresponding to the gross anat category\n",
    "    currentLabelReNum=np.where(np.isin(grossAnatList,grossAnatTable['GrossAnat'].loc[grossAnatTable['#No.']==uniqueAtlasEntries[iLabels]]))\n",
    "    relabeledAtlas[relabeledAtlas==uniqueAtlasEntries[iLabels]]=currentLabelReNum[0]\n",
    "\n",
    "grossAnatNifti=nib.Nifti1Image(relabeledAtlas, atlasImg.affine, atlasImg.header)  \n",
    "\n",
    "# load the tractography file into the streamsObjIN variable\n",
    "smallTractogramPath=os.path.join(gitRepoPath,'exampleData','smallTractogram.tck')\n",
    "streamsObjIN=nib.streamlines.load(smallTractogramPath)\n",
    "\n",
    "from dipy.tracking import utils\n",
    "#segment tractome into connectivity matrix from parcellation\n",
    "M, grouping=utils.connectivity_matrix(streamsObjIN.tractogram.streamlines, grossAnatNifti.affine, \\\n",
    "                        label_volume=grossAnatNifti.get_fdata().astype(int), \n",
    "                        return_mapping=True,\n",
    "                        mapping_as_streamlines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bb04ae8ddd4a6d812355122c023d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='region1', index=2, options=(('unknown', 0), ('wm', 1), ('ventricleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.updateFunction(regionIndex1, regionIndex2)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get tractogram from the Tck holder\n",
    "sourceTractogram=streamsObjIN.tractogram\n",
    "\n",
    "#quick and dirty tractogram subsetter by Brad Caron\n",
    "#https://github.com/bacaron\n",
    "def extractSubTractogram(sourceTractogram,indexes):\n",
    "    #import relevant package\n",
    "    import nibabel as nib\n",
    "    #extrect the desired streamlines into a new streamline object\n",
    "    streamlines = sourceTractogram.streamlines[indexes]\n",
    "    #establish tractogram object\n",
    "    out_tractogram = nib.streamlines.tractogram.Tractogram(streamlines)\n",
    "    #adjust the relevant header fields\n",
    "    #don't bother for now, header is only relevant to Tck file\n",
    "    #for headerFields in ['total_count','count','nb_streamlines']:\n",
    "        #nb_streamlines is an int, whereas the others are strings, for some reason\n",
    "    #    if headerFields == 'nb_streamlines':\n",
    "    #        out_tractogram.header[headerFields] = len(streamlines)\n",
    "    #    else:\n",
    "    #        out_tractogram.header[headerFields] = '%s' %len(streamlines)\n",
    "    return out_tractogram\n",
    "\n",
    "#interactive plotting via niwidgets?  \n",
    "#widget within a widget doesn't seem to work\n",
    "def plotParcellationConnectionWidget(subTractogram):\n",
    "    #import widget\n",
    "    from niwidgets import StreamlineWidget\n",
    "    #set widget object\n",
    "    \n",
    "    sw = StreamlineWidget(streamlines=subTractogram)\n",
    "    #set plotting characteristics\n",
    "    style = {'axes': {'color': 'red',\n",
    "                  'label': {'color': 'white'},\n",
    "                  'ticklabel': {'color': 'white'},\n",
    "                  'visible': False},\n",
    "         'background-color': 'black',\n",
    "         'box': {'visible': False}}\n",
    "    #plot it\n",
    "    sw.plot(display_fraction=1, width=1000, height=1000, style=style, percentile=0)\n",
    "\n",
    "def plotTract(tractIn):\n",
    "    import numpy as np\n",
    "    from dipy.viz import window, actor\n",
    "    renderer = window.Scene()\n",
    "    stream_actor = actor.line(tractIn)\n",
    "    #renderer.set_camera(position=(-176.42, 118.52, 128.20),\n",
    "    #               focal_point=(113.30, 128.31, 76.56),\n",
    "    #                view_up=(0.18, 0.00, 0.98))\n",
    "    %matplotlib inline\n",
    "    renderer.add(stream_actor)\n",
    "    \n",
    "    window.show(renderer, size=(600, 600), reset_camera=True)\n",
    "\n",
    "def updateFunction(regionIndex1,regionIndex2):\n",
    "    currentRenumberIndex1=regionIndex1    \n",
    "    currentRenumberIndex2=regionIndex2   \n",
    " \n",
    "    \n",
    "    #check to make sure this pairing is actually in the connections\n",
    "    if np.logical_or((currentRenumberIndex1,currentRenumberIndex2) in grouping.keys(),(currentRenumberIndex1,currentRenumberIndex2) in grouping.keys()): \n",
    "        #if they are both there do it (dipy method may preclude this)\n",
    "        if np.logical_and((currentRenumberIndex1,currentRenumberIndex2) in grouping.keys(),(currentRenumberIndex1,currentRenumberIndex2) in grouping.keys()): \n",
    "            currentIndexes=np.concatenate((np.asarray(grouping[currentRenumberIndex1,currentRenumberIndex2]),np.asarray(grouping[currentRenumberIndex2,currentRenumberIndex1]))).astype(int)\n",
    "        elif (currentRenumberIndex1,currentRenumberIndex2) in grouping.keys():\n",
    "            currentIndexes=grouping[currentRenumberIndex1,currentRenumberIndex2]\n",
    "        elif (currentRenumberIndex2,currentRenumberIndex1) in grouping.keys():\n",
    "            currentIndexes=grouping[currentRenumberIndex2,currentRenumberIndex1]\n",
    "        #there are no other potential cases\n",
    "        subTractogram=extractSubTractogram(sourceTractogram,currentIndexes)\n",
    "        %matplotlib inline\n",
    "        plotParcellationConnectionWidget(subTractogram.streamlines)\n",
    "    else:\n",
    "        print('connection not present')\n",
    "\n",
    "dropDownList=list(zip(grossAnatList, range(len(grossAnatList))))\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import Dropdown\n",
    "\n",
    "#establish interactivity\n",
    "interact(updateFunction, \n",
    "         regionIndex1=Dropdown(options=dropDownList, value=9, description=\"region1\"), \n",
    "         regionIndex2=Dropdown(options=dropDownList, value=12, description=\"region2\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish more specific endpoint criteria (loosely)\n",
    "In order to prevent certian spurrious streamlines (potentially implausable, and certianly not part of the uncinate) we can include some additional segmentation logic to exclude these streamlines *while also not being so strict as to make the segmentation brittle or overdetermined*.  Two of these loose endpoint criteria will be necessary for the uncinate.  Given that we require the posterior cluster of streamlines to be located in the anterior temporal region we can implement criteria relative to the  dorso-ventral axis and the rostro-caudal axis. \n",
    " \n",
    "###  Dorso-ventral criteria:\n",
    "In general, the endpoints of the uncinate are fairly low in the brain.\n",
    "Furthermore, we note that the arc of the uncinate occurs relatively close to the amygdala.  Because the streamlines of the uncinate approach from the ventral side of the amygdala (as they then proceed anteriorly to the frontal lobes), and reach their apex at around the top of the amygdala, it is necessarily the case that at least one endpoint of these streamlines (namely the posterior/inferior endpoint) is below the top of the amygdala.  Therefore, it is logically necessary that it is *not* the case that both streamline endpoints are superior to the top of the amygdala (or else it couldn't engage in the arcing behavior).  Lets translate this into segmentation logic.\n",
    "\n",
    "First we will begin by generating a plane from the top of the amygdala.  Then we find all streamlines that have **both** streamline endpointsabove this plane (we'll negate this criteria later, to adhere to our logic). Note, using the plane in this way is different than requiring neither streamline to be above this plane.  **This logical operation still permits maximally one endpoint per streamline to be above this plane** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rostro-caudal criteria\n",
    "\n",
    "In general, the endpoints of the uncinate are fairly *anterior* in the brain as we noted above, the arc of the uncinate occurs relatively close to the amygdala. This is true of the rostro-caudal axis as well. The streamlines of the uncinate have all begun to arc forward anterior of the posterior of the border of the amygdala.  A consequence, similar to the one noted (in bold) in the dorso-ventral criteria discussion, is that it is *not* the case that both endpoints are posterior of this posterior amygdala border.  Lets translate this into segmentation logic.\n",
    "\n",
    "We will begin by generating a plane from the posterior of the amygdala.  Next, we will use this to find all streamlines that have both streamline endpoints posterior to this plane (we'll negate this criteria later, to adhere to our logic). Note, this is different than requiring neither streamline to be anterior to this plane.  **This logical operation still permits maximally one endpoint per streamline to be posterior to\n",
    "this plane**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other anatomical criteria\n",
    "\n",
    "### midpoint rostro-caudal criteria:\n",
    "\n",
    "If the arc of the uncinate occurs anterior to the posterior border of the amygdala, it stands to reason that the midpoint of those streamlines would also occur anterior to this border.  Even in the case of more sigmoidally shaped streamlines (as opposed to u or j shaped), which do occur and have their endpoints potentially posterior to the posterior amygdala, the midpoint would still be anterior of this border if the anterior endpoint is to terminate in the anterior frontal lobes.  This can rather straightforwardly be translated into segmentation logic.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### posterior non-traversal criteria:\n",
    "\n",
    "As it should have been clear by now the category segmentation isinsufficient to isolate the uncinate.  Use bsc_quickPlotClassByName(wbfg,categoryClassification,'left_frontal_to_temporalto confirm this for yourself.  Note that the majority of thenon-uncinate fibers appear to be arcuate fibers.  How can we excludethese fibers?  By applying a plane that selectively targets the arcuate streamlines.\n",
    "\n",
    "Subcortical structures, like the thalamus (and amygdala), tend to be relatively invariant in their location across subjects.  This isfortunate for us, because it looks like all of the arcuate-like fibersextend *past* the posterior of the thalamus.  Lets generate a planar roi that we can use as an exclusion criterion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
